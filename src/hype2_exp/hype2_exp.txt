Traceback (most recent call last):
  File "run_experiments.py", line 3, in <module>
    from doe import *
ModuleNotFoundError: No module named 'doe'
kernel.numa_balancing = 0
numa_balancing=off
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-39
OMP: Info #156: KMP_AFFINITY: 40 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 2 packages x 10 cores/pkg x 2 threads/core (20 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 20 maps to package 0 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 21 maps to package 0 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 22 maps to package 0 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 23 maps to package 0 core 3 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 4 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 24 maps to package 0 core 4 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 8 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 25 maps to package 0 core 8 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 9 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 26 maps to package 0 core 9 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 10 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 27 maps to package 0 core 10 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 8 maps to package 0 core 11 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 28 maps to package 0 core 11 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 9 maps to package 0 core 12 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 29 maps to package 0 core 12 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 10 maps to package 1 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 30 maps to package 1 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 11 maps to package 1 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 31 maps to package 1 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 12 maps to package 1 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 32 maps to package 1 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 13 maps to package 1 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 33 maps to package 1 core 3 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 14 maps to package 1 core 4 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 34 maps to package 1 core 4 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 15 maps to package 1 core 8 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 35 maps to package 1 core 8 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 16 maps to package 1 core 9 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 36 maps to package 1 core 9 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 17 maps to package 1 core 10 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 37 maps to package 1 core 10 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 18 maps to package 1 core 11 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 38 maps to package 1 core 11 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 19 maps to package 1 core 12 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 39 maps to package 1 core 12 thread 1 
OMP: Info #144: KMP_AFFINITY: Threads may migrate across 1 innermost levels of machine
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7464 thread 0 bound to OS proc set 0,20
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7625 thread 1 bound to OS proc set 0,20
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7627 thread 3 bound to OS proc set 1,21
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7628 thread 4 bound to OS proc set 2,22
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7626 thread 2 bound to OS proc set 1,21
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7629 thread 5 bound to OS proc set 2,22
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7630 thread 6 bound to OS proc set 3,23
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7631 thread 7 bound to OS proc set 3,23
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7632 thread 8 bound to OS proc set 4,24
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7633 thread 9 bound to OS proc set 4,24
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7634 thread 10 bound to OS proc set 5,25
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7635 thread 11 bound to OS proc set 5,25
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7636 thread 12 bound to OS proc set 6,26
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7637 thread 13 bound to OS proc set 6,26
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7638 thread 14 bound to OS proc set 7,27
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7639 thread 15 bound to OS proc set 7,27
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7640 thread 16 bound to OS proc set 8,28
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7641 thread 17 bound to OS proc set 8,28
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7642 thread 18 bound to OS proc set 9,29
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7643 thread 19 bound to OS proc set 9,29
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7644 thread 20 bound to OS proc set 10,30
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7645 thread 21 bound to OS proc set 10,30
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7646 thread 22 bound to OS proc set 11,31
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7647 thread 23 bound to OS proc set 11,31
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7648 thread 24 bound to OS proc set 12,32
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7649 thread 25 bound to OS proc set 12,32
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7650 thread 26 bound to OS proc set 13,33
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7651 thread 27 bound to OS proc set 13,33
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7652 thread 28 bound to OS proc set 14,34
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7653 thread 29 bound to OS proc set 14,34
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7654 thread 30 bound to OS proc set 15,35
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7655 thread 31 bound to OS proc set 15,35
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7656 thread 32 bound to OS proc set 16,36
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7657 thread 33 bound to OS proc set 16,36
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7658 thread 34 bound to OS proc set 17,37
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7659 thread 35 bound to OS proc set 17,37
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7660 thread 36 bound to OS proc set 18,38
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7661 thread 37 bound to OS proc set 18,38
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7662 thread 38 bound to OS proc set 19,39
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7663 thread 39 bound to OS proc set 19,39
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7664 thread 40 bound to OS proc set 0,20
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7624 thread 41 bound to OS proc set 0,20
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7668 thread 42 bound to OS proc set 1,21
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7669 thread 43 bound to OS proc set 1,21
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7670 thread 44 bound to OS proc set 2,22
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7671 thread 45 bound to OS proc set 2,22
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7672 thread 46 bound to OS proc set 3,23
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7674 thread 48 bound to OS proc set 4,24
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7673 thread 47 bound to OS proc set 3,23
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7675 thread 49 bound to OS proc set 4,24
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7676 thread 50 bound to OS proc set 5,25
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7677 thread 51 bound to OS proc set 5,25
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7678 thread 52 bound to OS proc set 6,26
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7679 thread 53 bound to OS proc set 6,26
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7680 thread 54 bound to OS proc set 7,27
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7681 thread 55 bound to OS proc set 7,27
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7682 thread 56 bound to OS proc set 8,28
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7683 thread 57 bound to OS proc set 8,28
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7685 thread 59 bound to OS proc set 9,29
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7684 thread 58 bound to OS proc set 9,29
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7686 thread 60 bound to OS proc set 10,30
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7687 thread 61 bound to OS proc set 10,30
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7688 thread 62 bound to OS proc set 11,31
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7689 thread 63 bound to OS proc set 11,31
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7690 thread 64 bound to OS proc set 12,32
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7691 thread 65 bound to OS proc set 12,32
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7692 thread 66 bound to OS proc set 13,33
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7693 thread 67 bound to OS proc set 13,33
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7694 thread 68 bound to OS proc set 14,34
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7695 thread 69 bound to OS proc set 14,34
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7696 thread 70 bound to OS proc set 15,35
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7697 thread 71 bound to OS proc set 15,35
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7698 thread 72 bound to OS proc set 16,36
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7699 thread 73 bound to OS proc set 16,36
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7700 thread 74 bound to OS proc set 17,37
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7701 thread 75 bound to OS proc set 17,37
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7702 thread 76 bound to OS proc set 18,38
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7704 thread 78 bound to OS proc set 19,39
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7703 thread 77 bound to OS proc set 18,38
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7705 thread 79 bound to OS proc set 19,39
OMP: Info #250: KMP_AFFINITY: pid 7464 tid 7706 thread 80 bound to OS proc set 0,20

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 159 ± 6 ms
1.2 - training  | batch=50, size=224x224: 1150 ± 686 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 468 ± 93 ms
2.2 - training  | batch=20, size=346x346: 2112 ± 876 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 552 ± 100 ms
3.2 - training  | batch=10, size=346x346: 1794 ± 113 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 839 ± 102 ms
4.2 - training  | batch=8, size=346x346: 9478 ± 1339 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 488 ± 78 ms
5.2 - training  | batch=10, size=346x346: 2783 ± 967 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 690 ± 78 ms
6.2 - training  | batch=10, size=256x256: 7638 ± 1667 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 626 ± 6 ms
7.2 - training  | batch=2, size=224x224: 809 ± 97 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 758 ± 7 ms
8.2 - inference | batch=1, size=1536x1536: 690 ± 8 ms
8.3 - training  | batch=10, size=512x512: 2902 ± 55 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 680 ± 5 ms
9.2 - inference | batch=1, size=1024x1024: 1171 ± 2 ms
9.3 - training  | batch=10, size=224x224: 3586 ± 103 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 2348 ± 11 ms
10.2 - inference | batch=1, size=1536x1536: 2122 ± 12 ms
10.3 - training  | batch=5, size=512x512: 4148 ± 144 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 2205 ± 66 ms
11.2 - inference | batch=1, size=1024x1024: 3560 ± 56 ms
11.3 - training  | batch=15, size=128x128: 3817 ± 54 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 4647 ± 68 ms
12.2 - inference | batch=1, size=1024x1024: 4827 ± 126 ms
12.3 - training  | batch=4, size=256x256: 4234 ± 29 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1528 ± 82 ms
13.2 - training  | batch=1, size=128x128: 1994 ± 101 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1675 ± 97 ms
14.2 - training  | batch=10, size=1024x1536: 3866 ± 162 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7670 ± 99 ms
15.2 - training  | batch=1, size=512x512: 4409 ± 541 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2351 ± 117 ms
16.2 - training  | batch=1, size=384x384: 5090 ± 672 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5368 ± 45 ms
17.2 - training  | batch=10, size=64x64: 9466.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12384 ± 142 ms
18.2 - training  | batch=10, size=1024x300: 8079 ± 145 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1457 ± 150 ms

Device Inference Score: 951
Device Training Score: 846
Device AI Score: 1797

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 302 ± 68 ms
1.2 - training  | batch=50, size=224x224: 3652 ± 219 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 684 ± 94 ms
2.2 - training  | batch=20, size=346x346: 4084 ± 498 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 676 ± 90 ms
3.2 - training  | batch=10, size=346x346: 5881 ± 91 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1045 ± 108 ms
4.2 - training  | batch=8, size=346x346: 10167 ± 1069 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 535 ± 86 ms
5.2 - training  | batch=10, size=346x346: 3422 ± 496 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 863 ± 102 ms
6.2 - training  | batch=10, size=256x256: 7546 ± 225 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1187 ± 43 ms
7.2 - training  | batch=2, size=224x224: 822 ± 75 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1319 ± 37 ms
8.2 - inference | batch=1, size=1536x1536: 1209 ± 39 ms
8.3 - training  | batch=10, size=512x512: 3358 ± 99 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1344 ± 49 ms
9.2 - inference | batch=1, size=1024x1024: 2197 ± 68 ms
9.3 - training  | batch=10, size=224x224: 3700 ± 47 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3248 ± 69 ms
10.2 - inference | batch=1, size=1536x1536: 3016 ± 100 ms
10.3 - training  | batch=5, size=512x512: 4597 ± 90 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3120 ± 63 ms
11.2 - inference | batch=1, size=1024x1024: 5048 ± 93 ms
11.3 - training  | batch=15, size=128x128: 3816 ± 55 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5290 ± 93 ms
12.2 - inference | batch=1, size=1024x1024: 5566 ± 115 ms
12.3 - training  | batch=4, size=256x256: 4406 ± 67 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1488 ± 82 ms
13.2 - training  | batch=1, size=128x128: 2020 ± 83 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1666 ± 94 ms
14.2 - training  | batch=10, size=1024x1536: 3914 ± 117 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7480 ± 60 ms
15.2 - training  | batch=1, size=512x512: 5120 ± 278 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2430 ± 107 ms
16.2 - training  | batch=1, size=384x384: 5276 ± 225 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5520 ± 107 ms
17.2 - training  | batch=10, size=64x64: 9572.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12748 ± 87 ms
18.2 - training  | batch=10, size=1024x300: 8261 ± 239 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1431 ± 163 ms

Device Inference Score: 726
Device Training Score: 683
Device AI Score: 1409

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 288 ± 68 ms
1.2 - training  | batch=50, size=224x224: 3955 ± 180 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 675 ± 79 ms
2.2 - training  | batch=20, size=346x346: 5201 ± 144 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 704 ± 95 ms
3.2 - training  | batch=10, size=346x346: 5940 ± 1136 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1082 ± 98 ms
4.2 - training  | batch=8, size=346x346: 9091 ± 140 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 586 ± 95 ms
5.2 - training  | batch=10, size=346x346: 3740 ± 159 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 944 ± 94 ms
6.2 - training  | batch=10, size=256x256: 9276 ± 381 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1235 ± 48 ms
7.2 - training  | batch=2, size=224x224: 828 ± 83 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1320 ± 33 ms
8.2 - inference | batch=1, size=1536x1536: 1211 ± 28 ms
8.3 - training  | batch=10, size=512x512: 3335 ± 81 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1443 ± 49 ms
9.2 - inference | batch=1, size=1024x1024: 2243 ± 21 ms
9.3 - training  | batch=10, size=224x224: 3665 ± 79 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3368 ± 78 ms
10.2 - inference | batch=1, size=1536x1536: 3038 ± 133 ms
10.3 - training  | batch=5, size=512x512: 4499 ± 42 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3149 ± 91 ms
11.2 - inference | batch=1, size=1024x1024: 5120 ± 97 ms
11.3 - training  | batch=15, size=128x128: 3925 ± 80 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5341 ± 115 ms
12.2 - inference | batch=1, size=1024x1024: 5612 ± 67 ms
12.3 - training  | batch=4, size=256x256: 4447 ± 68 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1491 ± 94 ms
13.2 - training  | batch=1, size=128x128: 1985 ± 63 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1409 ± 62 ms
14.2 - training  | batch=10, size=1024x1536: 3480 ± 58 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 5054 ± 44 ms
15.2 - training  | batch=1, size=512x512: 2768 ± 363 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 1773 ± 157 ms
16.2 - training  | batch=1, size=384x384: 1614 ± 162 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5298 ± 247 ms
17.2 - training  | batch=10, size=64x64: 9598.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12127 ± 169 ms
18.2 - training  | batch=10, size=1024x300: 8164 ± 144 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1497 ± 98 ms

Device Inference Score: 741
Device Training Score: 739
Device AI Score: 1480

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 257 ± 59 ms
1.2 - training  | batch=50, size=224x224: 3858 ± 227 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 650 ± 86 ms
2.2 - training  | batch=20, size=346x346: 4462 ± 463 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 691 ± 92 ms
3.2 - training  | batch=10, size=346x346: 3007 ± 997 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 870 ± 129 ms
4.2 - training  | batch=8, size=346x346: 3249 ± 774 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 507 ± 81 ms
5.2 - training  | batch=10, size=346x346: 2633 ± 807 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 692 ± 76 ms
6.2 - training  | batch=10, size=256x256: 7663 ± 1156 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 630 ± 6 ms
7.2 - training  | batch=2, size=224x224: 809 ± 86 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 757 ± 14 ms
8.2 - inference | batch=1, size=1536x1536: 702 ± 12 ms
8.3 - training  | batch=10, size=512x512: 2897 ± 35 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 682 ± 4 ms
9.2 - inference | batch=1, size=1024x1024: 1179 ± 15 ms
9.3 - training  | batch=10, size=224x224: 3459 ± 109 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 2358 ± 9 ms
10.2 - inference | batch=1, size=1536x1536: 2146 ± 18 ms
10.3 - training  | batch=5, size=512x512: 4097 ± 100 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 2260 ± 81 ms
11.2 - inference | batch=1, size=1024x1024: 3615 ± 57 ms
11.3 - training  | batch=15, size=128x128: 3813 ± 63 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 4732 ± 63 ms
12.2 - inference | batch=1, size=1024x1024: 4885 ± 26 ms
12.3 - training  | batch=4, size=256x256: 4192 ± 136 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1458 ± 83 ms
13.2 - training  | batch=1, size=128x128: 2040 ± 62 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1655 ± 92 ms
14.2 - training  | batch=10, size=1024x1536: 3868 ± 143 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7595 ± 65 ms
15.2 - training  | batch=1, size=512x512: 4968 ± 146 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2312 ± 90 ms
16.2 - training  | batch=1, size=384x384: 5023 ± 184 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5396 ± 79 ms
17.2 - training  | batch=10, size=64x64: 9288.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11480 ± 138 ms
18.2 - training  | batch=10, size=1024x300: 8354 ± 81 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1516 ± 169 ms

Device Inference Score: 908
Device Training Score: 781
Device AI Score: 1689

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 273 ± 61 ms
1.2 - training  | batch=50, size=224x224: 3802 ± 280 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 646 ± 84 ms
2.2 - training  | batch=20, size=346x346: 4951 ± 275 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 666 ± 89 ms
3.2 - training  | batch=10, size=346x346: 6492 ± 789 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1032 ± 93 ms
4.2 - training  | batch=8, size=346x346: 10240 ± 400 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 554 ± 93 ms
5.2 - training  | batch=10, size=346x346: 3325 ± 387 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 920 ± 103 ms
6.2 - training  | batch=10, size=256x256: 8106 ± 553 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1211 ± 46 ms
7.2 - training  | batch=2, size=224x224: 871 ± 92 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1298 ± 41 ms
8.2 - inference | batch=1, size=1536x1536: 1187 ± 25 ms
8.3 - training  | batch=10, size=512x512: 3344 ± 31 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1402 ± 54 ms
9.2 - inference | batch=1, size=1024x1024: 2226 ± 65 ms
9.3 - training  | batch=10, size=224x224: 3692 ± 72 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3307 ± 59 ms
10.2 - inference | batch=1, size=1536x1536: 3005 ± 69 ms
10.3 - training  | batch=5, size=512x512: 4512 ± 66 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3192 ± 76 ms
11.2 - inference | batch=1, size=1024x1024: 5178 ± 72 ms
11.3 - training  | batch=15, size=128x128: 3985 ± 85 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5386 ± 153 ms
12.2 - inference | batch=1, size=1024x1024: 5528 ± 132 ms
12.3 - training  | batch=4, size=256x256: 4502 ± 149 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1461 ± 74 ms
13.2 - training  | batch=1, size=128x128: 1981 ± 69 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1444 ± 86 ms
14.2 - training  | batch=10, size=1024x1536: 3418 ± 52 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 5136 ± 83 ms
15.2 - training  | batch=1, size=512x512: 2658 ± 132 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 1794 ± 204 ms
16.2 - training  | batch=1, size=384x384: 2755 ± 1685 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5238 ± 75 ms
17.2 - training  | batch=10, size=64x64: 10000.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11796 ± 529 ms
18.2 - training  | batch=10, size=1024x300: 8197 ± 213 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1774 ± 190 ms

Device Inference Score: 748
Device Training Score: 720
Device AI Score: 1468

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 280 ± 65 ms
1.2 - training  | batch=50, size=224x224: 4194 ± 189 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 681 ± 95 ms
2.2 - training  | batch=20, size=346x346: 4904 ± 94 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 715 ± 102 ms
3.2 - training  | batch=10, size=346x346: 7313 ± 164 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1143 ± 99 ms
4.2 - training  | batch=8, size=346x346: 9460 ± 910 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 517 ± 80 ms
5.2 - training  | batch=10, size=346x346: 2321 ± 986 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 681 ± 51 ms
6.2 - training  | batch=10, size=256x256: 8543 ± 509 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 632 ± 7 ms
7.2 - training  | batch=2, size=224x224: 820 ± 93 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 762 ± 8 ms
8.2 - inference | batch=1, size=1536x1536: 710 ± 9 ms
8.3 - training  | batch=10, size=512x512: 2929 ± 67 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 683 ± 4 ms
9.2 - inference | batch=1, size=1024x1024: 1181 ± 19 ms
9.3 - training  | batch=10, size=224x224: 3635 ± 76 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 2375 ± 20 ms
10.2 - inference | batch=1, size=1536x1536: 2164 ± 25 ms
10.3 - training  | batch=5, size=512x512: 4065 ± 156 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 2226 ± 55 ms
11.2 - inference | batch=1, size=1024x1024: 3641 ± 75 ms
11.3 - training  | batch=15, size=128x128: 3720 ± 118 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 4653 ± 45 ms
12.2 - inference | batch=1, size=1024x1024: 4799 ± 66 ms
12.3 - training  | batch=4, size=256x256: 4380 ± 95 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1532 ± 103 ms
13.2 - training  | batch=1, size=128x128: 2026 ± 93 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1663 ± 81 ms
14.2 - training  | batch=10, size=1024x1536: 3886 ± 54 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7612 ± 79 ms
15.2 - training  | batch=1, size=512x512: 4840 ± 115 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2328 ± 66 ms
16.2 - training  | batch=1, size=384x384: 6330 ± 55 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5543 ± 102 ms
17.2 - training  | batch=10, size=64x64: 9916.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11296 ± 187 ms
18.2 - training  | batch=10, size=1024x300: 8161 ± 119 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1501 ± 158 ms

Device Inference Score: 889
Device Training Score: 682
Device AI Score: 1571

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 280 ± 66 ms
1.2 - training  | batch=50, size=224x224: 3768 ± 246 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 670 ± 81 ms
2.2 - training  | batch=20, size=346x346: 4415 ± 582 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 677 ± 93 ms
3.2 - training  | batch=10, size=346x346: 6078 ± 1062 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1096 ± 94 ms
4.2 - training  | batch=8, size=346x346: 9843 ± 173 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 565 ± 104 ms
5.2 - training  | batch=10, size=346x346: 3152 ± 534 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 894 ± 107 ms
6.2 - training  | batch=10, size=256x256: 6952 ± 976 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1214 ± 41 ms
7.2 - training  | batch=2, size=224x224: 835 ± 88 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1308 ± 51 ms
8.2 - inference | batch=1, size=1536x1536: 1179 ± 43 ms
8.3 - training  | batch=10, size=512x512: 3342 ± 69 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1391 ± 42 ms
9.2 - inference | batch=1, size=1024x1024: 2189 ± 20 ms
9.3 - training  | batch=10, size=224x224: 3684 ± 44 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3282 ± 71 ms
10.2 - inference | batch=1, size=1536x1536: 2994 ± 94 ms
10.3 - training  | batch=5, size=512x512: 4543 ± 84 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3211 ± 80 ms
11.2 - inference | batch=1, size=1024x1024: 5075 ± 64 ms
11.3 - training  | batch=15, size=128x128: 3894 ± 110 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5339 ± 109 ms
12.2 - inference | batch=1, size=1024x1024: 5546 ± 204 ms
12.3 - training  | batch=4, size=256x256: 4368 ± 158 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1475 ± 93 ms
13.2 - training  | batch=1, size=128x128: 1934 ± 64 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1437 ± 105 ms
14.2 - training  | batch=10, size=1024x1536: 3521 ± 65 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 5090 ± 81 ms
15.2 - training  | batch=1, size=512x512: 3026 ± 666 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 1850 ± 193 ms
16.2 - training  | batch=1, size=384x384: 1644 ± 161 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5621 ± 158 ms
17.2 - training  | batch=10, size=64x64: 9285.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 10946 ± 79 ms
18.2 - training  | batch=10, size=1024x300: 7953 ± 329 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1793 ± 201 ms

Device Inference Score: 745
Device Training Score: 762
Device AI Score: 1507

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 281 ± 68 ms
1.2 - training  | batch=50, size=224x224: 4009 ± 160 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 684 ± 89 ms
2.2 - training  | batch=20, size=346x346: 4979 ± 197 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 694 ± 87 ms
3.2 - training  | batch=10, size=346x346: 6413 ± 84 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1089 ± 98 ms
4.2 - training  | batch=8, size=346x346: 10206 ± 325 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 516 ± 75 ms
5.2 - training  | batch=10, size=346x346: 3060 ± 1003 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 695 ± 73 ms
6.2 - training  | batch=10, size=256x256: 6820 ± 2835 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 630 ± 7 ms
7.2 - training  | batch=2, size=224x224: 798 ± 90 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 770 ± 10 ms
8.2 - inference | batch=1, size=1536x1536: 703 ± 7 ms
8.3 - training  | batch=10, size=512x512: 2933 ± 92 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 682 ± 5 ms
9.2 - inference | batch=1, size=1024x1024: 1182 ± 11 ms
9.3 - training  | batch=10, size=224x224: 3473 ± 75 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 2350 ± 20 ms
10.2 - inference | batch=1, size=1536x1536: 2133 ± 19 ms
10.3 - training  | batch=5, size=512x512: 4242 ± 135 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 2128 ± 76 ms
11.2 - inference | batch=1, size=1024x1024: 3577 ± 47 ms
11.3 - training  | batch=15, size=128x128: 3691 ± 108 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 4600 ± 79 ms
12.2 - inference | batch=1, size=1024x1024: 4874 ± 73 ms
12.3 - training  | batch=4, size=256x256: 4230 ± 82 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1459 ± 96 ms
13.2 - training  | batch=1, size=128x128: 1984 ± 107 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1685 ± 92 ms
14.2 - training  | batch=10, size=1024x1536: 3917 ± 118 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7534 ± 49 ms
15.2 - training  | batch=1, size=512x512: 4839 ± 121 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2322 ± 123 ms
16.2 - training  | batch=1, size=384x384: 5511 ± 401 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5376 ± 123 ms
17.2 - training  | batch=10, size=64x64: 10199.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 13187 ± 113 ms
18.2 - training  | batch=10, size=1024x300: 7957 ± 383 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1490 ± 118 ms

Device Inference Score: 892
Device Training Score: 692
Device AI Score: 1584

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 295 ± 70 ms
1.2 - training  | batch=50, size=224x224: 3887 ± 291 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 643 ± 84 ms
2.2 - training  | batch=20, size=346x346: 4497 ± 170 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 672 ± 106 ms
3.2 - training  | batch=10, size=346x346: 6816 ± 554 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1060 ± 113 ms
4.2 - training  | batch=8, size=346x346: 8894 ± 179 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 560 ± 89 ms
5.2 - training  | batch=10, size=346x346: 3695 ± 180 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 911 ± 106 ms
6.2 - training  | batch=10, size=256x256: 8697 ± 527 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1212 ± 39 ms
7.2 - training  | batch=2, size=224x224: 799 ± 83 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1290 ± 47 ms
8.2 - inference | batch=1, size=1536x1536: 1216 ± 32 ms
8.3 - training  | batch=10, size=512x512: 3302 ± 75 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1395 ± 57 ms
9.2 - inference | batch=1, size=1024x1024: 2210 ± 60 ms
9.3 - training  | batch=10, size=224x224: 3641 ± 77 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3240 ± 64 ms
10.2 - inference | batch=1, size=1536x1536: 2991 ± 74 ms
10.3 - training  | batch=5, size=512x512: 4511 ± 77 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3151 ± 89 ms
11.2 - inference | batch=1, size=1024x1024: 4924 ± 28 ms
11.3 - training  | batch=15, size=128x128: 4005 ± 44 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5255 ± 60 ms
12.2 - inference | batch=1, size=1024x1024: 5536 ± 103 ms
12.3 - training  | batch=4, size=256x256: 4478 ± 81 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1459 ± 94 ms
13.2 - training  | batch=1, size=128x128: 1985 ± 63 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1662 ± 85 ms
14.2 - training  | batch=10, size=1024x1536: 3868 ± 101 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7569 ± 64 ms
15.2 - training  | batch=1, size=512x512: 4867 ± 224 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2293 ± 51 ms
16.2 - training  | batch=1, size=384x384: 4780 ± 505 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5463 ± 139 ms
17.2 - training  | batch=10, size=64x64: 10147.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11328 ± 88 ms
18.2 - training  | batch=10, size=1024x300: 8042 ± 347 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1428 ± 129 ms

Device Inference Score: 731
Device Training Score: 675
Device AI Score: 1406

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 292 ± 68 ms
1.2 - training  | batch=50, size=224x224: 4051 ± 114 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 669 ± 73 ms
2.2 - training  | batch=20, size=346x346: 5036 ± 161 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 690 ± 94 ms
3.2 - training  | batch=10, size=346x346: 7012 ± 128 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1074 ± 105 ms
4.2 - training  | batch=8, size=346x346: 10669 ± 46 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 585 ± 95 ms
5.2 - training  | batch=10, size=346x346: 3758 ± 157 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 905 ± 97 ms
6.2 - training  | batch=10, size=256x256: 8971 ± 428 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1201 ± 38 ms
7.2 - training  | batch=2, size=224x224: 824 ± 85 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1278 ± 34 ms
8.2 - inference | batch=1, size=1536x1536: 1207 ± 53 ms
8.3 - training  | batch=10, size=512x512: 3191 ± 74 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1446 ± 63 ms
9.2 - inference | batch=1, size=1024x1024: 2213 ± 21 ms
9.3 - training  | batch=10, size=224x224: 3715 ± 61 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3211 ± 71 ms
10.2 - inference | batch=1, size=1536x1536: 2899 ± 85 ms
10.3 - training  | batch=5, size=512x512: 4490 ± 67 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3079 ± 23 ms
11.2 - inference | batch=1, size=1024x1024: 4924 ± 47 ms
11.3 - training  | batch=15, size=128x128: 3879 ± 56 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5261 ± 134 ms
12.2 - inference | batch=1, size=1024x1024: 5395 ± 152 ms
12.3 - training  | batch=4, size=256x256: 4345 ± 70 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1490 ± 76 ms
13.2 - training  | batch=1, size=128x128: 2057 ± 59 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1649 ± 76 ms
14.2 - training  | batch=10, size=1024x1536: 3886 ± 116 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7367 ± 50 ms
15.2 - training  | batch=1, size=512x512: 4930 ± 97 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2302 ± 44 ms
16.2 - training  | batch=1, size=384x384: 5616 ± 566 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5473 ± 211 ms
17.2 - training  | batch=10, size=64x64: 10190.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12620 ± 198 ms
18.2 - training  | batch=10, size=1024x300: 8231 ± 282 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1471 ± 92 ms

Device Inference Score: 726
Device Training Score: 652
Device AI Score: 1378

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 242 ± 52 ms
1.2 - training  | batch=50, size=224x224: 3900 ± 64 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 683 ± 94 ms
2.2 - training  | batch=20, size=346x346: 4817 ± 213 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 696 ± 81 ms
3.2 - training  | batch=10, size=346x346: 6305 ± 517 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1044 ± 106 ms
4.2 - training  | batch=8, size=346x346: 10129 ± 483 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 577 ± 77 ms
5.2 - training  | batch=10, size=346x346: 3906 ± 159 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 898 ± 87 ms
6.2 - training  | batch=10, size=256x256: 8862 ± 994 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1178 ± 55 ms
7.2 - training  | batch=2, size=224x224: 857 ± 86 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1293 ± 50 ms
8.2 - inference | batch=1, size=1536x1536: 1172 ± 37 ms
8.3 - training  | batch=10, size=512x512: 3347 ± 68 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1367 ± 47 ms
9.2 - inference | batch=1, size=1024x1024: 2142 ± 27 ms
9.3 - training  | batch=10, size=224x224: 3725 ± 47 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3197 ± 70 ms
10.2 - inference | batch=1, size=1536x1536: 2916 ± 86 ms
10.3 - training  | batch=5, size=512x512: 4450 ± 82 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3140 ± 61 ms
11.2 - inference | batch=1, size=1024x1024: 5001 ± 54 ms
11.3 - training  | batch=15, size=128x128: 4020 ± 51 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5305 ± 110 ms
12.2 - inference | batch=1, size=1024x1024: 5471 ± 130 ms
12.3 - training  | batch=4, size=256x256: 4486 ± 101 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1504 ± 107 ms
13.2 - training  | batch=1, size=128x128: 2007 ± 84 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1672 ± 88 ms
14.2 - training  | batch=10, size=1024x1536: 3812 ± 119 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7658 ± 144 ms
15.2 - training  | batch=1, size=512x512: 4923 ± 168 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2317 ± 90 ms
16.2 - training  | batch=1, size=384x384: 6250 ± 125 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5366 ± 145 ms
17.2 - training  | batch=10, size=64x64: 9172.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11658 ± 739 ms
18.2 - training  | batch=10, size=1024x300: 8344 ± 248 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1486 ± 115 ms

Device Inference Score: 735
Device Training Score: 656
Device AI Score: 1391

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 292 ± 64 ms
1.2 - training  | batch=50, size=224x224: 4094 ± 96 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 677 ± 81 ms
2.2 - training  | batch=20, size=346x346: 4673 ± 122 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 700 ± 96 ms
3.2 - training  | batch=10, size=346x346: 7258 ± 433 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1098 ± 101 ms
4.2 - training  | batch=8, size=346x346: 9066 ± 1087 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 548 ± 93 ms
5.2 - training  | batch=10, size=346x346: 3929 ± 174 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 871 ± 96 ms
6.2 - training  | batch=10, size=256x256: 9323 ± 251 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1225 ± 52 ms
7.2 - training  | batch=2, size=224x224: 852 ± 83 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1272 ± 45 ms
8.2 - inference | batch=1, size=1536x1536: 1205 ± 53 ms
8.3 - training  | batch=10, size=512x512: 3298 ± 55 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1430 ± 48 ms
9.2 - inference | batch=1, size=1024x1024: 2235 ± 59 ms
9.3 - training  | batch=10, size=224x224: 3680 ± 65 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3282 ± 88 ms
10.2 - inference | batch=1, size=1536x1536: 2996 ± 65 ms
10.3 - training  | batch=5, size=512x512: 4577 ± 146 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3128 ± 107 ms
11.2 - inference | batch=1, size=1024x1024: 4920 ± 55 ms
11.3 - training  | batch=15, size=128x128: 3846 ± 70 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5300 ± 92 ms
12.2 - inference | batch=1, size=1024x1024: 5396 ± 150 ms
12.3 - training  | batch=4, size=256x256: 4511 ± 45 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1477 ± 78 ms
13.2 - training  | batch=1, size=128x128: 2018 ± 96 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1432 ± 77 ms
14.2 - training  | batch=10, size=1024x1536: 3423 ± 59 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 5082 ± 83 ms
15.2 - training  | batch=1, size=512x512: 2636 ± 123 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 1800 ± 152 ms
16.2 - training  | batch=1, size=384x384: 1807 ± 541 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5520 ± 162 ms
17.2 - training  | batch=10, size=64x64: 9108.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11192 ± 455 ms
18.2 - training  | batch=10, size=1024x300: 8137 ± 274 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1778 ± 185 ms

Device Inference Score: 746
Device Training Score: 730
Device AI Score: 1476

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 175 ± 21 ms
1.2 - training  | batch=50, size=224x224: 1024 ± 197 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 476 ± 66 ms
2.2 - training  | batch=20, size=346x346: 2538 ± 1220 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 554 ± 85 ms
3.2 - training  | batch=10, size=346x346: 5454 ± 1545 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 892 ± 92 ms
4.2 - training  | batch=8, size=346x346: 10718 ± 835 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 523 ± 78 ms
5.2 - training  | batch=10, size=346x346: 2386 ± 858 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 689 ± 52 ms
6.2 - training  | batch=10, size=256x256: 4829 ± 2171 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 632 ± 6 ms
7.2 - training  | batch=2, size=224x224: 820 ± 89 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 766 ± 9 ms
8.2 - inference | batch=1, size=1536x1536: 702 ± 7 ms
8.3 - training  | batch=10, size=512x512: 2960 ± 70 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 682 ± 6 ms
9.2 - inference | batch=1, size=1024x1024: 1168.9 ± 0.9 ms
9.3 - training  | batch=10, size=224x224: 3609 ± 149 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 2365 ± 12 ms
10.2 - inference | batch=1, size=1536x1536: 2037 ± 65 ms
10.3 - training  | batch=5, size=512x512: 4089 ± 200 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 2105 ± 56 ms
11.2 - inference | batch=1, size=1024x1024: 3592 ± 83 ms
11.3 - training  | batch=15, size=128x128: 3747 ± 110 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 4660 ± 89 ms
12.2 - inference | batch=1, size=1024x1024: 4853 ± 43 ms
12.3 - training  | batch=4, size=256x256: 4269 ± 139 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1451 ± 72 ms
13.2 - training  | batch=1, size=128x128: 1990 ± 100 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1680 ± 79 ms
14.2 - training  | batch=10, size=1024x1536: 3715 ± 62 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7559 ± 128 ms
15.2 - training  | batch=1, size=512x512: 4723 ± 158 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2320 ± 78 ms
16.2 - training  | batch=1, size=384x384: 5109 ± 171 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5412 ± 172 ms
17.2 - training  | batch=10, size=64x64: 9654.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12816 ± 167 ms
18.2 - training  | batch=10, size=1024x300: 8339 ± 183 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1479 ± 187 ms

Device Inference Score: 943
Device Training Score: 810
Device AI Score: 1753

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 297 ± 66 ms
1.2 - training  | batch=50, size=224x224: 3773 ± 109 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 670 ± 80 ms
2.2 - training  | batch=20, size=346x346: 4712 ± 291 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 683 ± 107 ms
3.2 - training  | batch=10, size=346x346: 5162 ± 341 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1049 ± 115 ms
4.2 - training  | batch=8, size=346x346: 10438 ± 1135 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 578 ± 94 ms
5.2 - training  | batch=10, size=346x346: 3891 ± 262 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 883 ± 94 ms
6.2 - training  | batch=10, size=256x256: 8815 ± 652 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1199 ± 39 ms
7.2 - training  | batch=2, size=224x224: 834 ± 78 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1322 ± 33 ms
8.2 - inference | batch=1, size=1536x1536: 1199 ± 43 ms
8.3 - training  | batch=10, size=512x512: 3274 ± 68 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1419 ± 62 ms
9.2 - inference | batch=1, size=1024x1024: 2227 ± 56 ms
9.3 - training  | batch=10, size=224x224: 3712 ± 38 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3189 ± 61 ms
10.2 - inference | batch=1, size=1536x1536: 2968 ± 90 ms
10.3 - training  | batch=5, size=512x512: 4444 ± 91 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3142 ± 77 ms
11.2 - inference | batch=1, size=1024x1024: 4922 ± 49 ms
11.3 - training  | batch=15, size=128x128: 3885 ± 113 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5228 ± 103 ms
12.2 - inference | batch=1, size=1024x1024: 5443 ± 159 ms
12.3 - training  | batch=4, size=256x256: 4169 ± 150 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1465 ± 73 ms
13.2 - training  | batch=1, size=128x128: 1914 ± 120 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1591 ± 79 ms
14.2 - training  | batch=10, size=1024x1536: 3766 ± 118 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7068 ± 103 ms
15.2 - training  | batch=1, size=512x512: 4134 ± 404 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2188 ± 67 ms
16.2 - training  | batch=1, size=384x384: 5262 ± 575 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5500 ± 202 ms
17.2 - training  | batch=10, size=64x64: 11340.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 13441 ± 593 ms
18.2 - training  | batch=10, size=1024x300: 8574 ± 76 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1529 ± 106 ms

Device Inference Score: 727
Device Training Score: 677
Device AI Score: 1404

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 240 ± 42 ms
1.2 - training  | batch=50, size=224x224: 3869 ± 127 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 663 ± 82 ms
2.2 - training  | batch=20, size=346x346: 4599 ± 182 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 706 ± 97 ms
3.2 - training  | batch=10, size=346x346: 4633 ± 487 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1023 ± 95 ms
4.2 - training  | batch=8, size=346x346: 10238 ± 309 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 571 ± 109 ms
5.2 - training  | batch=10, size=346x346: 3620 ± 330 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 901 ± 110 ms
6.2 - training  | batch=10, size=256x256: 7941 ± 331 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1196 ± 45 ms
7.2 - training  | batch=2, size=224x224: 843 ± 85 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1290 ± 53 ms
8.2 - inference | batch=1, size=1536x1536: 1186 ± 49 ms
8.3 - training  | batch=10, size=512x512: 3358 ± 62 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1444 ± 54 ms
9.2 - inference | batch=1, size=1024x1024: 2231 ± 23 ms
9.3 - training  | batch=10, size=224x224: 3695 ± 92 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3314 ± 115 ms
10.2 - inference | batch=1, size=1536x1536: 2989 ± 86 ms
10.3 - training  | batch=5, size=512x512: 4518 ± 58 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3221 ± 56 ms
11.2 - inference | batch=1, size=1024x1024: 5105 ± 86 ms
11.3 - training  | batch=15, size=128x128: 3850 ± 79 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5303 ± 51 ms
12.2 - inference | batch=1, size=1024x1024: 5499 ± 119 ms
12.3 - training  | batch=4, size=256x256: 4438 ± 42 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1522 ± 90 ms
13.2 - training  | batch=1, size=128x128: 1964 ± 123 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1647 ± 83 ms
14.2 - training  | batch=10, size=1024x1536: 3812 ± 94 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7546 ± 120 ms
15.2 - training  | batch=1, size=512x512: 4831 ± 192 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2335 ± 129 ms
16.2 - training  | batch=1, size=384x384: 5392 ± 249 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5344 ± 111 ms
17.2 - training  | batch=10, size=64x64: 11319.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11279 ± 95 ms
18.2 - training  | batch=10, size=1024x300: 8362 ± 130 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1571 ± 204 ms

Device Inference Score: 729
Device Training Score: 677
Device AI Score: 1406

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 296 ± 74 ms
1.2 - training  | batch=50, size=224x224: 4106 ± 292 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 689 ± 94 ms
2.2 - training  | batch=20, size=346x346: 4422 ± 165 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 699 ± 96 ms
3.2 - training  | batch=10, size=346x346: 5781 ± 736 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1064 ± 105 ms
4.2 - training  | batch=8, size=346x346: 10445 ± 255 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 562 ± 98 ms
5.2 - training  | batch=10, size=346x346: 3896 ± 194 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 875 ± 104 ms
6.2 - training  | batch=10, size=256x256: 9902 ± 449 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1223 ± 69 ms
7.2 - training  | batch=2, size=224x224: 861 ± 95 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1335 ± 49 ms
8.2 - inference | batch=1, size=1536x1536: 1155 ± 44 ms
8.3 - training  | batch=10, size=512x512: 3299 ± 97 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1502 ± 52 ms
9.2 - inference | batch=1, size=1024x1024: 2340 ± 42 ms
9.3 - training  | batch=10, size=224x224: 3754 ± 39 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3251 ± 72 ms
10.2 - inference | batch=1, size=1536x1536: 3029 ± 95 ms
10.3 - training  | batch=5, size=512x512: 4473 ± 115 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 2975 ± 41 ms
11.2 - inference | batch=1, size=1024x1024: 4989 ± 82 ms
11.3 - training  | batch=15, size=128x128: 3904 ± 33 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5321 ± 149 ms
12.2 - inference | batch=1, size=1024x1024: 5534 ± 84 ms
12.3 - training  | batch=4, size=256x256: 4391 ± 110 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1549 ± 87 ms
13.2 - training  | batch=1, size=128x128: 2062 ± 49 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1690 ± 83 ms
14.2 - training  | batch=10, size=1024x1536: 3942 ± 80 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7798 ± 78 ms
15.2 - training  | batch=1, size=512x512: 5226 ± 358 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2457 ± 97 ms
16.2 - training  | batch=1, size=384x384: 6419 ± 342 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5609 ± 97 ms
17.2 - training  | batch=10, size=64x64: 13028.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11756 ± 298 ms
18.2 - training  | batch=10, size=1024x300: 8009 ± 206 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1527 ± 139 ms

Device Inference Score: 716
Device Training Score: 640
Device AI Score: 1356

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 297 ± 68 ms
1.2 - training  | batch=50, size=224x224: 3876 ± 119 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 683 ± 79 ms
2.2 - training  | batch=20, size=346x346: 4425 ± 215 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 679 ± 93 ms
3.2 - training  | batch=10, size=346x346: 7176 ± 382 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1111 ± 117 ms
4.2 - training  | batch=8, size=346x346: 9739 ± 654 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 536 ± 88 ms
5.2 - training  | batch=10, size=346x346: 3684 ± 186 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 899 ± 99 ms
6.2 - training  | batch=10, size=256x256: 8622 ± 622 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1250 ± 45 ms
7.2 - training  | batch=2, size=224x224: 846 ± 91 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1331 ± 47 ms
8.2 - inference | batch=1, size=1536x1536: 1233 ± 45 ms
8.3 - training  | batch=10, size=512x512: 3341 ± 116 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1477 ± 46 ms
9.2 - inference | batch=1, size=1024x1024: 2304 ± 37 ms
9.3 - training  | batch=10, size=224x224: 3690 ± 45 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3314 ± 95 ms
10.2 - inference | batch=1, size=1536x1536: 3081 ± 72 ms
10.3 - training  | batch=5, size=512x512: 4516 ± 119 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3194 ± 84 ms
11.2 - inference | batch=1, size=1024x1024: 5002 ± 86 ms
11.3 - training  | batch=15, size=128x128: 3959 ± 103 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5388 ± 96 ms
12.2 - inference | batch=1, size=1024x1024: 5666 ± 134 ms
12.3 - training  | batch=4, size=256x256: 4592 ± 61 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1507 ± 76 ms
13.2 - training  | batch=1, size=128x128: 2044 ± 89 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1722 ± 77 ms
14.2 - training  | batch=10, size=1024x1536: 3989 ± 107 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7557 ± 76 ms
15.2 - training  | batch=1, size=512x512: 5250 ± 162 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2379 ± 89 ms
16.2 - training  | batch=1, size=384x384: 5909 ± 214 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5347 ± 179 ms
17.2 - training  | batch=10, size=64x64: 10202.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11898 ± 394 ms
18.2 - training  | batch=10, size=1024x300: 8128 ± 225 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1469 ± 147 ms

Device Inference Score: 715
Device Training Score: 654
Device AI Score: 1369

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 290 ± 63 ms
1.2 - training  | batch=50, size=224x224: 4064 ± 65 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 703 ± 93 ms
2.2 - training  | batch=20, size=346x346: 5087 ± 325 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 756 ± 94 ms
3.2 - training  | batch=10, size=346x346: 7444 ± 227 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1031 ± 113 ms
4.2 - training  | batch=8, size=346x346: 8780 ± 1062 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 587 ± 96 ms
5.2 - training  | batch=10, size=346x346: 3800 ± 107 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 907 ± 85 ms
6.2 - training  | batch=10, size=256x256: 8967 ± 1147 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1255 ± 42 ms
7.2 - training  | batch=2, size=224x224: 849 ± 98 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1338 ± 46 ms
8.2 - inference | batch=1, size=1536x1536: 1241 ± 46 ms
8.3 - training  | batch=10, size=512x512: 3440 ± 68 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1483 ± 72 ms
9.2 - inference | batch=1, size=1024x1024: 2281 ± 50 ms
9.3 - training  | batch=10, size=224x224: 3794 ± 78 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3324 ± 82 ms
10.2 - inference | batch=1, size=1536x1536: 3057 ± 87 ms
10.3 - training  | batch=5, size=512x512: 4632 ± 56 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3177 ± 83 ms
11.2 - inference | batch=1, size=1024x1024: 5079 ± 52 ms
11.3 - training  | batch=15, size=128x128: 3992 ± 102 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5362 ± 89 ms
12.2 - inference | batch=1, size=1024x1024: 5539 ± 163 ms
12.3 - training  | batch=4, size=256x256: 4473 ± 64 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1486 ± 77 ms
13.2 - training  | batch=1, size=128x128: 1984 ± 49 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1637 ± 82 ms
14.2 - training  | batch=10, size=1024x1536: 3896 ± 114 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7353 ± 123 ms
15.2 - training  | batch=1, size=512x512: 4567 ± 600 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2352 ± 91 ms
16.2 - training  | batch=1, size=384x384: 6198 ± 77 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5460 ± 190 ms
17.2 - training  | batch=10, size=64x64: 10134.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12606 ± 103 ms
18.2 - training  | batch=10, size=1024x300: 8488 ± 193 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1644 ± 83 ms

Device Inference Score: 708
Device Training Score: 648
Device AI Score: 1356

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 228 ± 48 ms
1.2 - training  | batch=50, size=224x224: 3530 ± 148 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 674 ± 78 ms
2.2 - training  | batch=20, size=346x346: 4037 ± 126 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 712 ± 90 ms
3.2 - training  | batch=10, size=346x346: 5558 ± 595 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1021 ± 97 ms
4.2 - training  | batch=8, size=346x346: 10200 ± 387 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 593 ± 92 ms
5.2 - training  | batch=10, size=346x346: 3219 ± 526 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 870 ± 89 ms
6.2 - training  | batch=10, size=256x256: 8288 ± 825 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1135 ± 34 ms
7.2 - training  | batch=2, size=224x224: 851 ± 88 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1295 ± 39 ms
8.2 - inference | batch=1, size=1536x1536: 1181 ± 15 ms
8.3 - training  | batch=10, size=512x512: 3353 ± 46 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1363 ± 49 ms
9.2 - inference | batch=1, size=1024x1024: 2168 ± 20 ms
9.3 - training  | batch=10, size=224x224: 3742 ± 64 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3226 ± 115 ms
10.2 - inference | batch=1, size=1536x1536: 3014 ± 68 ms
10.3 - training  | batch=5, size=512x512: 4511 ± 49 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3181 ± 72 ms
11.2 - inference | batch=1, size=1024x1024: 5063 ± 79 ms
11.3 - training  | batch=15, size=128x128: 3983 ± 87 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5283 ± 66 ms
12.2 - inference | batch=1, size=1024x1024: 5576 ± 96 ms
12.3 - training  | batch=4, size=256x256: 4545 ± 137 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1550 ± 103 ms
13.2 - training  | batch=1, size=128x128: 1986 ± 98 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1434 ± 81 ms
14.2 - training  | batch=10, size=1024x1536: 3663 ± 201 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 5110 ± 69 ms
15.2 - training  | batch=1, size=512x512: 3320 ± 911 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 1780 ± 147 ms
16.2 - training  | batch=1, size=384x384: 1780 ± 160 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5508 ± 198 ms
17.2 - training  | batch=10, size=64x64: 9973.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 10998 ± 104 ms
18.2 - training  | batch=10, size=1024x300: 8214 ± 125 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1739 ± 177 ms

Device Inference Score: 756
Device Training Score: 744
Device AI Score: 1500

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 272 ± 59 ms
1.2 - training  | batch=50, size=224x224: 3970 ± 67 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 684 ± 90 ms
2.2 - training  | batch=20, size=346x346: 4798 ± 105 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 722 ± 97 ms
3.2 - training  | batch=10, size=346x346: 6773 ± 247 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 897 ± 101 ms
4.2 - training  | batch=8, size=346x346: 4667 ± 2461 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 518 ± 68 ms
5.2 - training  | batch=10, size=346x346: 2894 ± 925 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 704 ± 61 ms
6.2 - training  | batch=10, size=256x256: 8070 ± 913 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 635 ± 6 ms
7.2 - training  | batch=2, size=224x224: 813 ± 83 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 768 ± 8 ms
8.2 - inference | batch=1, size=1536x1536: 700 ± 7 ms
8.3 - training  | batch=10, size=512x512: 2945 ± 83 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 682 ± 4 ms
9.2 - inference | batch=1, size=1024x1024: 1179 ± 11 ms
9.3 - training  | batch=10, size=224x224: 3530 ± 35 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 2390 ± 15 ms
10.2 - inference | batch=1, size=1536x1536: 2168 ± 15 ms
10.3 - training  | batch=5, size=512x512: 4223 ± 146 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 2221 ± 50 ms
11.2 - inference | batch=1, size=1024x1024: 3583 ± 49 ms
11.3 - training  | batch=15, size=128x128: 3911 ± 82 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 4772 ± 49 ms
12.2 - inference | batch=1, size=1024x1024: 4995 ± 43 ms
12.3 - training  | batch=4, size=256x256: 4252 ± 175 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1471 ± 95 ms
13.2 - training  | batch=1, size=128x128: 1987 ± 98 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1724 ± 87 ms
14.2 - training  | batch=10, size=1024x1536: 3992 ± 122 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7754 ± 214 ms
15.2 - training  | batch=1, size=512x512: 4606 ± 472 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2374 ± 86 ms
16.2 - training  | batch=1, size=384x384: 5156 ± 135 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5522 ± 130 ms
17.2 - training  | batch=10, size=64x64: 9960.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12934 ± 189 ms
18.2 - training  | batch=10, size=1024x300: 8366 ± 134 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1484 ± 122 ms

Device Inference Score: 890
Device Training Score: 716
Device AI Score: 1606

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 292 ± 72 ms
1.2 - training  | batch=50, size=224x224: 4005 ± 180 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 689 ± 94 ms
2.2 - training  | batch=20, size=346x346: 4358 ± 280 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 734 ± 122 ms
3.2 - training  | batch=10, size=346x346: 6868 ± 313 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1042 ± 119 ms
4.2 - training  | batch=8, size=346x346: 7533 ± 386 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 601 ± 93 ms
5.2 - training  | batch=10, size=346x346: 3785 ± 333 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 920 ± 108 ms
6.2 - training  | batch=10, size=256x256: 7919 ± 1423 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1217 ± 55 ms
7.2 - training  | batch=2, size=224x224: 875 ± 88 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1327 ± 31 ms
8.2 - inference | batch=1, size=1536x1536: 1221 ± 34 ms
8.3 - training  | batch=10, size=512x512: 3313 ± 80 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1409 ± 54 ms
9.2 - inference | batch=1, size=1024x1024: 2233 ± 64 ms
9.3 - training  | batch=10, size=224x224: 3662 ± 84 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3335 ± 19 ms
10.2 - inference | batch=1, size=1536x1536: 3055 ± 79 ms
10.3 - training  | batch=5, size=512x512: 4458 ± 72 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3174 ± 69 ms
11.2 - inference | batch=1, size=1024x1024: 5001 ± 114 ms
11.3 - training  | batch=15, size=128x128: 3828 ± 68 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5332 ± 61 ms
12.2 - inference | batch=1, size=1024x1024: 5598 ± 95 ms
12.3 - training  | batch=4, size=256x256: 4486 ± 48 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1479 ± 104 ms
13.2 - training  | batch=1, size=128x128: 2057 ± 66 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1682 ± 72 ms
14.2 - training  | batch=10, size=1024x1536: 3888 ± 143 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7558 ± 74 ms
15.2 - training  | batch=1, size=512x512: 5009 ± 215 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2355 ± 115 ms
16.2 - training  | batch=1, size=384x384: 6273 ± 283 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5684 ± 167 ms
17.2 - training  | batch=10, size=64x64: 10209.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11622 ± 316 ms
18.2 - training  | batch=10, size=1024x300: 8178 ± 154 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1557 ± 179 ms

Device Inference Score: 714
Device Training Score: 668
Device AI Score: 1382

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 290 ± 67 ms
1.2 - training  | batch=50, size=224x224: 4139 ± 47 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 702 ± 81 ms
2.2 - training  | batch=20, size=346x346: 4901 ± 192 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 704 ± 100 ms
3.2 - training  | batch=10, size=346x346: 6366 ± 249 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1024 ± 113 ms
4.2 - training  | batch=8, size=346x346: 9214 ± 1022 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 555 ± 84 ms
5.2 - training  | batch=10, size=346x346: 3905 ± 107 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 893 ± 94 ms
6.2 - training  | batch=10, size=256x256: 9040 ± 961 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1216 ± 45 ms
7.2 - training  | batch=2, size=224x224: 814 ± 73 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1289 ± 42 ms
8.2 - inference | batch=1, size=1536x1536: 1243 ± 55 ms
8.3 - training  | batch=10, size=512x512: 3365 ± 68 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1401 ± 52 ms
9.2 - inference | batch=1, size=1024x1024: 2253 ± 39 ms
9.3 - training  | batch=10, size=224x224: 3798 ± 38 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3332 ± 64 ms
10.2 - inference | batch=1, size=1536x1536: 3047 ± 88 ms
10.3 - training  | batch=5, size=512x512: 4452 ± 41 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3192 ± 32 ms
11.2 - inference | batch=1, size=1024x1024: 5134 ± 83 ms
11.3 - training  | batch=15, size=128x128: 3898 ± 110 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5388 ± 71 ms
12.2 - inference | batch=1, size=1024x1024: 5597 ± 137 ms
12.3 - training  | batch=4, size=256x256: 4486 ± 103 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1524 ± 56 ms
13.2 - training  | batch=1, size=128x128: 2006 ± 103 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1689 ± 98 ms
14.2 - training  | batch=10, size=1024x1536: 3872 ± 130 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7556 ± 130 ms
15.2 - training  | batch=1, size=512x512: 4858 ± 114 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2295 ± 93 ms
16.2 - training  | batch=1, size=384x384: 3682 ± 146 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5621 ± 143 ms
17.2 - training  | batch=10, size=64x64: 10070.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11337 ± 187 ms
18.2 - training  | batch=10, size=1024x300: 8169 ± 190 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1566 ± 174 ms

Device Inference Score: 718
Device Training Score: 674
Device AI Score: 1392

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 283 ± 73 ms
1.2 - training  | batch=50, size=224x224: 3661 ± 414 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 667 ± 77 ms
2.2 - training  | batch=20, size=346x346: 4861 ± 133 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 681 ± 103 ms
3.2 - training  | batch=10, size=346x346: 6537 ± 435 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1104 ± 91 ms
4.2 - training  | batch=8, size=346x346: 8594 ± 607 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 561 ± 90 ms
5.2 - training  | batch=10, size=346x346: 4070 ± 122 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 918 ± 88 ms
6.2 - training  | batch=10, size=256x256: 9074 ± 45 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1253 ± 52 ms
7.2 - training  | batch=2, size=224x224: 825 ± 85 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1307 ± 32 ms
8.2 - inference | batch=1, size=1536x1536: 1207 ± 50 ms
8.3 - training  | batch=10, size=512x512: 3389 ± 129 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1437 ± 55 ms
9.2 - inference | batch=1, size=1024x1024: 2286 ± 48 ms
9.3 - training  | batch=10, size=224x224: 3724 ± 70 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3203 ± 91 ms
10.2 - inference | batch=1, size=1536x1536: 2917 ± 87 ms
10.3 - training  | batch=5, size=512x512: 4566 ± 110 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3096 ± 78 ms
11.2 - inference | batch=1, size=1024x1024: 4871 ± 68 ms
11.3 - training  | batch=15, size=128x128: 3928 ± 70 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5321 ± 50 ms
12.2 - inference | batch=1, size=1024x1024: 5451 ± 97 ms
12.3 - training  | batch=4, size=256x256: 4473 ± 70 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1493 ± 89 ms
13.2 - training  | batch=1, size=128x128: 1977 ± 71 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1652 ± 87 ms
14.2 - training  | batch=10, size=1024x1536: 3948 ± 78 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7768 ± 117 ms
15.2 - training  | batch=1, size=512x512: 4718 ± 440 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2329 ± 93 ms
16.2 - training  | batch=1, size=384x384: 4984 ± 1293 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5410 ± 218 ms
17.2 - training  | batch=10, size=64x64: 10498.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11497 ± 501 ms
18.2 - training  | batch=10, size=1024x300: 8242 ± 92 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1581 ± 177 ms

Device Inference Score: 723
Device Training Score: 666
Device AI Score: 1389

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 284 ± 69 ms
1.2 - training  | batch=50, size=224x224: 4028 ± 80 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 663 ± 76 ms
2.2 - training  | batch=20, size=346x346: 5011 ± 105 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 701 ± 106 ms
3.2 - training  | batch=10, size=346x346: 7554 ± 115 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1043 ± 104 ms
4.2 - training  | batch=8, size=346x346: 10363 ± 285 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 569 ± 92 ms
5.2 - training  | batch=10, size=346x346: 3743 ± 70 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 909 ± 91 ms
6.2 - training  | batch=10, size=256x256: 9084 ± 182 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1199 ± 45 ms
7.2 - training  | batch=2, size=224x224: 857 ± 76 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1312 ± 54 ms
8.2 - inference | batch=1, size=1536x1536: 1220 ± 35 ms
8.3 - training  | batch=10, size=512x512: 3316 ± 87 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1378 ± 46 ms
9.2 - inference | batch=1, size=1024x1024: 2228 ± 59 ms
9.3 - training  | batch=10, size=224x224: 3702 ± 72 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3287 ± 120 ms
10.2 - inference | batch=1, size=1536x1536: 2988 ± 70 ms
10.3 - training  | batch=5, size=512x512: 4582 ± 164 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3180 ± 45 ms
11.2 - inference | batch=1, size=1024x1024: 5069 ± 69 ms
11.3 - training  | batch=15, size=128x128: 3929 ± 76 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5327 ± 82 ms
12.2 - inference | batch=1, size=1024x1024: 5637 ± 110 ms
12.3 - training  | batch=4, size=256x256: 4502 ± 132 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1509 ± 98 ms
13.2 - training  | batch=1, size=128x128: 1967 ± 67 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1642 ± 92 ms
14.2 - training  | batch=10, size=1024x1536: 3782 ± 105 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7464 ± 65 ms
15.2 - training  | batch=1, size=512x512: 5040 ± 180 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2286 ± 95 ms
16.2 - training  | batch=1, size=384x384: 5930 ± 117 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5452 ± 189 ms
17.2 - training  | batch=10, size=64x64: 11876.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11341 ± 82 ms
18.2 - training  | batch=10, size=1024x300: 8404 ± 57 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1499 ± 130 ms

Device Inference Score: 726
Device Training Score: 639
Device AI Score: 1365

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 297 ± 69 ms
1.2 - training  | batch=50, size=224x224: 3947 ± 76 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 636 ± 76 ms
2.2 - training  | batch=20, size=346x346: 4796 ± 87 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 685 ± 96 ms
3.2 - training  | batch=10, size=346x346: 5021 ± 213 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1061 ± 109 ms
4.2 - training  | batch=8, size=346x346: 9504 ± 540 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 548 ± 99 ms
5.2 - training  | batch=10, size=346x346: 3736 ± 206 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 876 ± 96 ms
6.2 - training  | batch=10, size=256x256: 9217 ± 285 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1193 ± 42 ms
7.2 - training  | batch=2, size=224x224: 856 ± 91 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1258 ± 61 ms
8.2 - inference | batch=1, size=1536x1536: 1159 ± 48 ms
8.3 - training  | batch=10, size=512x512: 3258 ± 70 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1395 ± 48 ms
9.2 - inference | batch=1, size=1024x1024: 2205 ± 60 ms
9.3 - training  | batch=10, size=224x224: 3717 ± 40 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3217 ± 92 ms
10.2 - inference | batch=1, size=1536x1536: 2924 ± 113 ms
10.3 - training  | batch=5, size=512x512: 4490 ± 117 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3093 ± 81 ms
11.2 - inference | batch=1, size=1024x1024: 4906 ± 58 ms
11.3 - training  | batch=15, size=128x128: 3866 ± 67 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5327 ± 68 ms
12.2 - inference | batch=1, size=1024x1024: 5455 ± 98 ms
12.3 - training  | batch=4, size=256x256: 4323 ± 39 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1485 ± 75 ms
13.2 - training  | batch=1, size=128x128: 2008 ± 68 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1677 ± 76 ms
14.2 - training  | batch=10, size=1024x1536: 3882 ± 127 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7624 ± 40 ms
15.2 - training  | batch=1, size=512x512: 4956 ± 151 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2364 ± 88 ms
16.2 - training  | batch=1, size=384x384: 6830 ± 308 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5398 ± 87 ms
17.2 - training  | batch=10, size=64x64: 10573.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11253 ± 94 ms
18.2 - training  | batch=10, size=1024x300: 8383 ± 176 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1526 ± 202 ms

Device Inference Score: 733
Device Training Score: 660
Device AI Score: 1393

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 263 ± 61 ms
1.2 - training  | batch=50, size=224x224: 3928 ± 326 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 667 ± 77 ms
2.2 - training  | batch=20, size=346x346: 4894 ± 24 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 666 ± 94 ms
3.2 - training  | batch=10, size=346x346: 6580 ± 121 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1078 ± 107 ms
4.2 - training  | batch=8, size=346x346: 10802 ± 380 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 556 ± 72 ms
5.2 - training  | batch=10, size=346x346: 3678 ± 231 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 916 ± 98 ms
6.2 - training  | batch=10, size=256x256: 9259 ± 171 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1202 ± 46 ms
7.2 - training  | batch=2, size=224x224: 864 ± 84 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1316 ± 29 ms
8.2 - inference | batch=1, size=1536x1536: 1236 ± 45 ms
8.3 - training  | batch=10, size=512x512: 3365 ± 69 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1404 ± 50 ms
9.2 - inference | batch=1, size=1024x1024: 2231 ± 17 ms
9.3 - training  | batch=10, size=224x224: 3729 ± 40 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3297 ± 78 ms
10.2 - inference | batch=1, size=1536x1536: 3031 ± 116 ms
10.3 - training  | batch=5, size=512x512: 4480 ± 114 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3120 ± 62 ms
11.2 - inference | batch=1, size=1024x1024: 5032 ± 40 ms
11.3 - training  | batch=15, size=128x128: 3942 ± 113 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5432 ± 84 ms
12.2 - inference | batch=1, size=1024x1024: 5558 ± 175 ms
12.3 - training  | batch=4, size=256x256: 4431 ± 123 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1522 ± 81 ms
13.2 - training  | batch=1, size=128x128: 1973 ± 58 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1651 ± 81 ms
14.2 - training  | batch=10, size=1024x1536: 3891 ± 70 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7676 ± 56 ms
15.2 - training  | batch=1, size=512x512: 5029 ± 258 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2321 ± 80 ms
16.2 - training  | batch=1, size=384x384: 6336 ± 212 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5410 ± 191 ms
17.2 - training  | batch=10, size=64x64: 10769.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11271 ± 83 ms
18.2 - training  | batch=10, size=1024x300: 8044 ± 236 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1540 ± 115 ms

Device Inference Score: 726
Device Training Score: 646
Device AI Score: 1372

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 299 ± 75 ms
1.2 - training  | batch=50, size=224x224: 4042 ± 76 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 689 ± 96 ms
2.2 - training  | batch=20, size=346x346: 5102 ± 360 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 697 ± 91 ms
3.2 - training  | batch=10, size=346x346: 6502 ± 254 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1091 ± 105 ms
4.2 - training  | batch=8, size=346x346: 10040 ± 277 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 573 ± 106 ms
5.2 - training  | batch=10, size=346x346: 3770 ± 506 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 894 ± 95 ms
6.2 - training  | batch=10, size=256x256: 9018 ± 142 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1197 ± 28 ms
7.2 - training  | batch=2, size=224x224: 819 ± 90 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1320 ± 54 ms
8.2 - inference | batch=1, size=1536x1536: 1217 ± 23 ms
8.3 - training  | batch=10, size=512x512: 3367 ± 118 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1374 ± 36 ms
9.2 - inference | batch=1, size=1024x1024: 2214 ± 27 ms
9.3 - training  | batch=10, size=224x224: 3694 ± 50 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3255 ± 66 ms
10.2 - inference | batch=1, size=1536x1536: 3006 ± 77 ms
10.3 - training  | batch=5, size=512x512: 4550 ± 146 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3138 ± 77 ms
11.2 - inference | batch=1, size=1024x1024: 5146 ± 49 ms
11.3 - training  | batch=15, size=128x128: 3895 ± 123 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5330 ± 19 ms
12.2 - inference | batch=1, size=1024x1024: 5449 ± 100 ms
12.3 - training  | batch=4, size=256x256: 4332 ± 82 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1462 ± 110 ms
13.2 - training  | batch=1, size=128x128: 1951 ± 84 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1668 ± 101 ms
14.2 - training  | batch=10, size=1024x1536: 3945 ± 130 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7670 ± 113 ms
15.2 - training  | batch=1, size=512x512: 4693 ± 391 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2355 ± 97 ms
16.2 - training  | batch=1, size=384x384: 6690 ± 264 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5555 ± 77 ms
17.2 - training  | batch=10, size=64x64: 13207.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11562 ± 439 ms
18.2 - training  | batch=10, size=1024x300: 7920 ± 204 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1538 ± 115 ms

Device Inference Score: 720
Device Training Score: 643
Device AI Score: 1363

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 267 ± 55 ms
1.2 - training  | batch=50, size=224x224: 3849 ± 298 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 662 ± 85 ms
2.2 - training  | batch=20, size=346x346: 4531 ± 464 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 678 ± 99 ms
3.2 - training  | batch=10, size=346x346: 7598 ± 462 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1075 ± 123 ms
4.2 - training  | batch=8, size=346x346: 9727 ± 535 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 581 ± 100 ms
5.2 - training  | batch=10, size=346x346: 3773 ± 85 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 900 ± 97 ms
6.2 - training  | batch=10, size=256x256: 9052 ± 430 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1259 ± 52 ms
7.2 - training  | batch=2, size=224x224: 858 ± 90 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1296 ± 45 ms
8.2 - inference | batch=1, size=1536x1536: 1195 ± 47 ms
8.3 - training  | batch=10, size=512x512: 3303 ± 77 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1454 ± 50 ms
9.2 - inference | batch=1, size=1024x1024: 2304 ± 32 ms
9.3 - training  | batch=10, size=224x224: 3705 ± 44 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3186 ± 79 ms
10.2 - inference | batch=1, size=1536x1536: 2785 ± 70 ms
10.3 - training  | batch=5, size=512x512: 4543 ± 25 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3065 ± 104 ms
11.2 - inference | batch=1, size=1024x1024: 4858 ± 19 ms
11.3 - training  | batch=15, size=128x128: 3879 ± 58 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5214 ± 131 ms
12.2 - inference | batch=1, size=1024x1024: 5570 ± 77 ms
12.3 - training  | batch=4, size=256x256: 4448 ± 114 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1460 ± 121 ms
13.2 - training  | batch=1, size=128x128: 1898 ± 88 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1408 ± 79 ms
14.2 - training  | batch=10, size=1024x1536: 3532 ± 77 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 5107 ± 64 ms
15.2 - training  | batch=1, size=512x512: 2719 ± 124 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 1791 ± 179 ms
16.2 - training  | batch=1, size=384x384: 1684 ± 180 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5728 ± 40 ms
17.2 - training  | batch=10, size=64x64: 9545.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 10867 ± 119 ms
18.2 - training  | batch=10, size=1024x300: 8253 ± 102 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1770 ± 197 ms

Device Inference Score: 750
Device Training Score: 733
Device AI Score: 1483

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 177 ± 16 ms
1.2 - training  | batch=50, size=224x224: 1062 ± 166 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 486 ± 86 ms
2.2 - training  | batch=20, size=346x346: 1895 ± 197 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 572 ± 67 ms
3.2 - training  | batch=10, size=346x346: 5294 ± 1864 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1093 ± 100 ms
4.2 - training  | batch=8, size=346x346: 10536 ± 483 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 523 ± 75 ms
5.2 - training  | batch=10, size=346x346: 3737 ± 269 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 683 ± 66 ms
6.2 - training  | batch=10, size=256x256: 4986 ± 2598 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 632 ± 6 ms
7.2 - training  | batch=2, size=224x224: 817 ± 81 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 754 ± 7 ms
8.2 - inference | batch=1, size=1536x1536: 702 ± 12 ms
8.3 - training  | batch=10, size=512x512: 2874 ± 47 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 684 ± 7 ms
9.2 - inference | batch=1, size=1024x1024: 1183 ± 17 ms
9.3 - training  | batch=10, size=224x224: 3538 ± 54 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 2357 ± 14 ms
10.2 - inference | batch=1, size=1536x1536: 2141 ± 31 ms
10.3 - training  | batch=5, size=512x512: 4212 ± 171 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 2096 ± 70 ms
11.2 - inference | batch=1, size=1024x1024: 3586 ± 53 ms
11.3 - training  | batch=15, size=128x128: 3664 ± 220 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 4623 ± 66 ms
12.2 - inference | batch=1, size=1024x1024: 4857 ± 93 ms
12.3 - training  | batch=4, size=256x256: 4196 ± 57 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1487 ± 93 ms
13.2 - training  | batch=1, size=128x128: 1858 ± 130 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1434 ± 101 ms
14.2 - training  | batch=10, size=1024x1536: 3388 ± 47 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 5055 ± 79 ms
15.2 - training  | batch=1, size=512x512: 2978 ± 585 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 1726 ± 132 ms
16.2 - training  | batch=1, size=384x384: 3315 ± 1706 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5390 ± 20 ms
17.2 - training  | batch=10, size=64x64: 9910.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12022 ± 264 ms
18.2 - training  | batch=10, size=1024x300: 8253 ± 132 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1554 ± 96 ms

Device Inference Score: 965
Device Training Score: 853
Device AI Score: 1818

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 167 ± 13 ms
1.2 - training  | batch=50, size=224x224: 1075 ± 255 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 525 ± 80 ms
2.2 - training  | batch=20, size=346x346: 2411 ± 1173 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 526 ± 83 ms
3.2 - training  | batch=10, size=346x346: 4753 ± 939 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1052 ± 98 ms
4.2 - training  | batch=8, size=346x346: 9672 ± 453 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 548 ± 83 ms
5.2 - training  | batch=10, size=346x346: 3868 ± 154 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 886 ± 89 ms
6.2 - training  | batch=10, size=256x256: 8787 ± 723 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1183 ± 38 ms
7.2 - training  | batch=2, size=224x224: 849 ± 87 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1279 ± 48 ms
8.2 - inference | batch=1, size=1536x1536: 1188 ± 48 ms
8.3 - training  | batch=10, size=512x512: 3347 ± 122 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1386 ± 50 ms
9.2 - inference | batch=1, size=1024x1024: 2210 ± 55 ms
9.3 - training  | batch=10, size=224x224: 3670 ± 38 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3318 ± 99 ms
10.2 - inference | batch=1, size=1536x1536: 3055 ± 71 ms
10.3 - training  | batch=5, size=512x512: 4410 ± 117 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3208 ± 57 ms
11.2 - inference | batch=1, size=1024x1024: 5133 ± 113 ms
11.3 - training  | batch=15, size=128x128: 3860 ± 57 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5344 ± 57 ms
12.2 - inference | batch=1, size=1024x1024: 5533 ± 208 ms
12.3 - training  | batch=4, size=256x256: 4406 ± 62 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1471 ± 78 ms
13.2 - training  | batch=1, size=128x128: 1948 ± 66 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1657 ± 98 ms
14.2 - training  | batch=10, size=1024x1536: 3875 ± 125 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7529 ± 94 ms
15.2 - training  | batch=1, size=512x512: 4244 ± 645 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2352 ± 76 ms
16.2 - training  | batch=1, size=384x384: 6088 ± 351 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5438 ± 30 ms
17.2 - training  | batch=10, size=64x64: 10105.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11282 ± 147 ms
18.2 - training  | batch=10, size=1024x300: 8148 ± 280 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1468 ± 120 ms

Device Inference Score: 761
Device Training Score: 755
Device AI Score: 1516

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 249 ± 38 ms
1.2 - training  | batch=50, size=224x224: 3866 ± 293 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 670 ± 90 ms
2.2 - training  | batch=20, size=346x346: 4658 ± 373 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 680 ± 100 ms
3.2 - training  | batch=10, size=346x346: 7323 ± 191 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1043 ± 105 ms
4.2 - training  | batch=8, size=346x346: 10343 ± 133 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 553 ± 86 ms
5.2 - training  | batch=10, size=346x346: 2935 ± 307 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 905 ± 109 ms
6.2 - training  | batch=10, size=256x256: 8569 ± 671 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1202 ± 62 ms
7.2 - training  | batch=2, size=224x224: 832 ± 79 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1304 ± 37 ms
8.2 - inference | batch=1, size=1536x1536: 1236 ± 39 ms
8.3 - training  | batch=10, size=512x512: 3332 ± 85 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1401 ± 55 ms
9.2 - inference | batch=1, size=1024x1024: 2244 ± 52 ms
9.3 - training  | batch=10, size=224x224: 3711 ± 56 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3252 ± 90 ms
10.2 - inference | batch=1, size=1536x1536: 3027 ± 61 ms
10.3 - training  | batch=5, size=512x512: 4561 ± 49 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3193 ± 65 ms
11.2 - inference | batch=1, size=1024x1024: 5129 ± 90 ms
11.3 - training  | batch=15, size=128x128: 3834 ± 67 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5323 ± 86 ms
12.2 - inference | batch=1, size=1024x1024: 5580 ± 115 ms
12.3 - training  | batch=4, size=256x256: 4426 ± 125 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1454 ± 78 ms
13.2 - training  | batch=1, size=128x128: 1983 ± 47 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1667 ± 62 ms
14.2 - training  | batch=10, size=1024x1536: 3940 ± 115 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7464 ± 50 ms
15.2 - training  | batch=1, size=512x512: 4880 ± 213 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2297 ± 88 ms
16.2 - training  | batch=1, size=384x384: 5410 ± 122 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5591 ± 137 ms
17.2 - training  | batch=10, size=64x64: 9729.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12666 ± 138 ms
18.2 - training  | batch=10, size=1024x300: 8235 ± 352 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1507 ± 130 ms

Device Inference Score: 726
Device Training Score: 669
Device AI Score: 1395

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 285 ± 80 ms
1.2 - training  | batch=50, size=224x224: 4006 ± 64 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 658 ± 104 ms
2.2 - training  | batch=20, size=346x346: 4707 ± 482 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 678 ± 92 ms
3.2 - training  | batch=10, size=346x346: 6588 ± 192 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1072 ± 106 ms
4.2 - training  | batch=8, size=346x346: 10131 ± 724 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 554 ± 88 ms
5.2 - training  | batch=10, size=346x346: 3834 ± 159 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 868 ± 102 ms
6.2 - training  | batch=10, size=256x256: 9339 ± 182 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1175 ± 46 ms
7.2 - training  | batch=2, size=224x224: 837 ± 95 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1340 ± 33 ms
8.2 - inference | batch=1, size=1536x1536: 1215 ± 29 ms
8.3 - training  | batch=10, size=512x512: 3374 ± 83 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1445 ± 43 ms
9.2 - inference | batch=1, size=1024x1024: 2284 ± 51 ms
9.3 - training  | batch=10, size=224x224: 3760 ± 77 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3196 ± 63 ms
10.2 - inference | batch=1, size=1536x1536: 2938 ± 97 ms
10.3 - training  | batch=5, size=512x512: 4473 ± 46 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3178 ± 71 ms
11.2 - inference | batch=1, size=1024x1024: 4891 ± 89 ms
11.3 - training  | batch=15, size=128x128: 3883 ± 106 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5158 ± 91 ms
12.2 - inference | batch=1, size=1024x1024: 5579 ± 153 ms
12.3 - training  | batch=4, size=256x256: 4372 ± 41 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1488 ± 85 ms
13.2 - training  | batch=1, size=128x128: 2003 ± 106 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1676 ± 102 ms
14.2 - training  | batch=10, size=1024x1536: 3878 ± 80 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7514 ± 94 ms
15.2 - training  | batch=1, size=512x512: 5065 ± 135 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2276 ± 114 ms
16.2 - training  | batch=1, size=384x384: 5295 ± 100 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5812 ± 147 ms
17.2 - training  | batch=10, size=64x64: 9569.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12913 ± 99 ms
18.2 - training  | batch=10, size=1024x300: 8383 ± 37 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1513 ± 170 ms

Device Inference Score: 723
Device Training Score: 658
Device AI Score: 1381

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 297 ± 61 ms
1.2 - training  | batch=50, size=224x224: 4004 ± 94 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 716 ± 83 ms
2.2 - training  | batch=20, size=346x346: 4471 ± 413 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 727 ± 97 ms
3.2 - training  | batch=10, size=346x346: 6394 ± 558 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1093 ± 123 ms
4.2 - training  | batch=8, size=346x346: 10922 ± 338 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 548 ± 99 ms
5.2 - training  | batch=10, size=346x346: 3570 ± 224 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 872 ± 114 ms
6.2 - training  | batch=10, size=256x256: 8890 ± 959 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1256 ± 58 ms
7.2 - training  | batch=2, size=224x224: 803 ± 83 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1323 ± 33 ms
8.2 - inference | batch=1, size=1536x1536: 1218 ± 47 ms
8.3 - training  | batch=10, size=512x512: 3350 ± 111 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1354 ± 45 ms
9.2 - inference | batch=1, size=1024x1024: 2176 ± 17 ms
9.3 - training  | batch=10, size=224x224: 3699 ± 60 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3206 ± 109 ms
10.2 - inference | batch=1, size=1536x1536: 2958 ± 59 ms
10.3 - training  | batch=5, size=512x512: 4478 ± 139 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3071 ± 59 ms
11.2 - inference | batch=1, size=1024x1024: 4966 ± 101 ms
11.3 - training  | batch=15, size=128x128: 3886 ± 54 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5318 ± 128 ms
12.2 - inference | batch=1, size=1024x1024: 5525 ± 88 ms
12.3 - training  | batch=4, size=256x256: 4341 ± 246 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1440 ± 107 ms
13.2 - training  | batch=1, size=128x128: 1889 ± 74 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1665 ± 79 ms
14.2 - training  | batch=10, size=1024x1536: 3940 ± 70 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7831 ± 125 ms
15.2 - training  | batch=1, size=512x512: 5230 ± 221 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2362 ± 97 ms
16.2 - training  | batch=1, size=384x384: 5654 ± 262 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5618 ± 114 ms
17.2 - training  | batch=10, size=64x64: 9879.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11569 ± 425 ms
18.2 - training  | batch=10, size=1024x300: 8421 ± 156 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1555 ± 156 ms

Device Inference Score: 721
Device Training Score: 662
Device AI Score: 1383

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 282 ± 73 ms
1.2 - training  | batch=50, size=224x224: 4193 ± 286 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 686 ± 93 ms
2.2 - training  | batch=20, size=346x346: 4763 ± 133 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 726 ± 93 ms
3.2 - training  | batch=10, size=346x346: 6804 ± 252 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1099 ± 116 ms
4.2 - training  | batch=8, size=346x346: 10812 ± 487 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 574 ± 67 ms
5.2 - training  | batch=10, size=346x346: 3854 ± 194 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 901 ± 100 ms
6.2 - training  | batch=10, size=256x256: 8323 ± 348 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1222 ± 52 ms
7.2 - training  | batch=2, size=224x224: 851 ± 92 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1313 ± 23 ms
8.2 - inference | batch=1, size=1536x1536: 1206 ± 26 ms
8.3 - training  | batch=10, size=512x512: 3316 ± 79 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1468 ± 39 ms
9.2 - inference | batch=1, size=1024x1024: 2313 ± 35 ms
9.3 - training  | batch=10, size=224x224: 3685 ± 61 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3220 ± 99 ms
10.2 - inference | batch=1, size=1536x1536: 2982 ± 95 ms
10.3 - training  | batch=5, size=512x512: 4570 ± 123 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3032 ± 67 ms
11.2 - inference | batch=1, size=1024x1024: 4925 ± 61 ms
11.3 - training  | batch=15, size=128x128: 3883 ± 63 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5312 ± 48 ms
12.2 - inference | batch=1, size=1024x1024: 5465 ± 152 ms
12.3 - training  | batch=4, size=256x256: 4433 ± 43 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1526 ± 98 ms
13.2 - training  | batch=1, size=128x128: 1987 ± 87 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1641 ± 86 ms
14.2 - training  | batch=10, size=1024x1536: 3889 ± 81 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7604 ± 68 ms
15.2 - training  | batch=1, size=512x512: 4532 ± 263 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2326 ± 116 ms
16.2 - training  | batch=1, size=384x384: 6056 ± 122 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5573 ± 73 ms
17.2 - training  | batch=10, size=64x64: 10814.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11378 ± 63 ms
18.2 - training  | batch=10, size=1024x300: 8516 ± 107 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1577 ± 143 ms

Device Inference Score: 719
Device Training Score: 650
Device AI Score: 1369

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 293 ± 63 ms
1.2 - training  | batch=50, size=224x224: 4119 ± 117 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 675 ± 89 ms
2.2 - training  | batch=20, size=346x346: 5021 ± 133 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 676 ± 86 ms
3.2 - training  | batch=10, size=346x346: 6942 ± 56 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1062 ± 115 ms
4.2 - training  | batch=8, size=346x346: 10312 ± 670 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 547 ± 80 ms
5.2 - training  | batch=10, size=346x346: 3810 ± 73 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 879 ± 103 ms
6.2 - training  | batch=10, size=256x256: 9918 ± 51 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1229 ± 47 ms
7.2 - training  | batch=2, size=224x224: 823 ± 98 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1312 ± 35 ms
8.2 - inference | batch=1, size=1536x1536: 1207 ± 40 ms
8.3 - training  | batch=10, size=512x512: 3313 ± 48 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1426 ± 48 ms
9.2 - inference | batch=1, size=1024x1024: 2210 ± 23 ms
9.3 - training  | batch=10, size=224x224: 3713 ± 83 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3200 ± 95 ms
10.2 - inference | batch=1, size=1536x1536: 2923 ± 73 ms
10.3 - training  | batch=5, size=512x512: 4546 ± 83 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3016 ± 44 ms
11.2 - inference | batch=1, size=1024x1024: 4897 ± 78 ms
11.3 - training  | batch=15, size=128x128: 3860 ± 75 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5185 ± 108 ms
12.2 - inference | batch=1, size=1024x1024: 5376 ± 162 ms
12.3 - training  | batch=4, size=256x256: 4415 ± 136 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1480 ± 85 ms
13.2 - training  | batch=1, size=128x128: 1991 ± 46 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1672 ± 104 ms
14.2 - training  | batch=10, size=1024x1536: 3791 ± 93 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7686 ± 90 ms
15.2 - training  | batch=1, size=512x512: 4950 ± 86 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2403 ± 117 ms
16.2 - training  | batch=1, size=384x384: 6653 ± 167 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5588 ± 142 ms
17.2 - training  | batch=10, size=64x64: 10076.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11326 ± 75 ms
18.2 - training  | batch=10, size=1024x300: 8281 ± 240 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1469 ± 129 ms

Device Inference Score: 730
Device Training Score: 643
Device AI Score: 1373

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 286 ± 70 ms
1.2 - training  | batch=50, size=224x224: 4046 ± 78 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 683 ± 91 ms
2.2 - training  | batch=20, size=346x346: 5020 ± 104 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 684 ± 98 ms
3.2 - training  | batch=10, size=346x346: 5743 ± 1104 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1028 ± 100 ms
4.2 - training  | batch=8, size=346x346: 9336 ± 1151 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 550 ± 87 ms
5.2 - training  | batch=10, size=346x346: 3585 ± 665 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 900 ± 100 ms
6.2 - training  | batch=10, size=256x256: 8775 ± 635 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1193 ± 41 ms
7.2 - training  | batch=2, size=224x224: 849 ± 84 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1314 ± 22 ms
8.2 - inference | batch=1, size=1536x1536: 1224 ± 26 ms
8.3 - training  | batch=10, size=512x512: 3336 ± 74 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1410 ± 52 ms
9.2 - inference | batch=1, size=1024x1024: 2190 ± 22 ms
9.3 - training  | batch=10, size=224x224: 3747 ± 51 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3321 ± 73 ms
10.2 - inference | batch=1, size=1536x1536: 3023 ± 75 ms
10.3 - training  | batch=5, size=512x512: 4534 ± 133 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3147 ± 44 ms
11.2 - inference | batch=1, size=1024x1024: 5059 ± 85 ms
11.3 - training  | batch=15, size=128x128: 3886 ± 62 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5409 ± 94 ms
12.2 - inference | batch=1, size=1024x1024: 5541 ± 89 ms
12.3 - training  | batch=4, size=256x256: 4438 ± 68 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1498 ± 89 ms
13.2 - training  | batch=1, size=128x128: 1989 ± 86 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1657 ± 82 ms
14.2 - training  | batch=10, size=1024x1536: 3944 ± 71 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7526 ± 60 ms
15.2 - training  | batch=1, size=512x512: 4782 ± 278 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2312 ± 80 ms
16.2 - training  | batch=1, size=384x384: 6455 ± 228 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5616 ± 222 ms
17.2 - training  | batch=10, size=64x64: 9509.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12317 ± 71 ms
18.2 - training  | batch=10, size=1024x300: 7839 ± 118 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1516 ± 174 ms

Device Inference Score: 722
Device Training Score: 664
Device AI Score: 1386

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 276 ± 73 ms
1.2 - training  | batch=50, size=224x224: 3733 ± 170 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 682 ± 82 ms
2.2 - training  | batch=20, size=346x346: 4780 ± 265 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 692 ± 88 ms
3.2 - training  | batch=10, size=346x346: 7069 ± 152 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1051 ± 96 ms
4.2 - training  | batch=8, size=346x346: 10166 ± 557 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 595 ± 101 ms
5.2 - training  | batch=10, size=346x346: 3675 ± 84 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 897 ± 102 ms
6.2 - training  | batch=10, size=256x256: 9034 ± 140 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1242 ± 46 ms
7.2 - training  | batch=2, size=224x224: 837 ± 97 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1281 ± 65 ms
8.2 - inference | batch=1, size=1536x1536: 1208 ± 32 ms
8.3 - training  | batch=10, size=512x512: 3343 ± 48 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1426 ± 50 ms
9.2 - inference | batch=1, size=1024x1024: 2217 ± 54 ms
9.3 - training  | batch=10, size=224x224: 3621 ± 33 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3234 ± 138 ms
10.2 - inference | batch=1, size=1536x1536: 3001 ± 88 ms
10.3 - training  | batch=5, size=512x512: 4481 ± 76 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3100 ± 60 ms
11.2 - inference | batch=1, size=1024x1024: 4846 ± 56 ms
11.3 - training  | batch=15, size=128x128: 3956 ± 88 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5257 ± 77 ms
12.2 - inference | batch=1, size=1024x1024: 5435 ± 64 ms
12.3 - training  | batch=4, size=256x256: 4480 ± 69 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1489 ± 81 ms
13.2 - training  | batch=1, size=128x128: 2051 ± 60 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1663 ± 97 ms
14.2 - training  | batch=10, size=1024x1536: 3888 ± 120 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7786 ± 62 ms
15.2 - training  | batch=1, size=512x512: 4716 ± 445 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2355 ± 123 ms
16.2 - training  | batch=1, size=384x384: 6305 ± 47 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5542 ± 42 ms
17.2 - training  | batch=10, size=64x64: 10160.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12275 ± 132 ms
18.2 - training  | batch=10, size=1024x300: 8355 ± 151 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1469 ± 126 ms

Device Inference Score: 723
Device Training Score: 653
Device AI Score: 1376

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 299 ± 75 ms
1.2 - training  | batch=50, size=224x224: 3992 ± 131 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 677 ± 83 ms
2.2 - training  | batch=20, size=346x346: 4778 ± 97 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 698 ± 97 ms
3.2 - training  | batch=10, size=346x346: 5343 ± 568 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1052 ± 107 ms
4.2 - training  | batch=8, size=346x346: 7431 ± 1653 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 565 ± 92 ms
5.2 - training  | batch=10, size=346x346: 3673 ± 141 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 895 ± 101 ms
6.2 - training  | batch=10, size=256x256: 9390 ± 174 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1196 ± 41 ms
7.2 - training  | batch=2, size=224x224: 826 ± 88 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1315 ± 38 ms
8.2 - inference | batch=1, size=1536x1536: 1215 ± 46 ms
8.3 - training  | batch=10, size=512x512: 3327 ± 63 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1415 ± 59 ms
9.2 - inference | batch=1, size=1024x1024: 2237 ± 59 ms
9.3 - training  | batch=10, size=224x224: 3737 ± 90 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3200 ± 84 ms
10.2 - inference | batch=1, size=1536x1536: 2967 ± 76 ms
10.3 - training  | batch=5, size=512x512: 4544 ± 104 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3103 ± 51 ms
11.2 - inference | batch=1, size=1024x1024: 4899 ± 60 ms
11.3 - training  | batch=15, size=128x128: 3905 ± 49 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5290 ± 82 ms
12.2 - inference | batch=1, size=1024x1024: 5515 ± 117 ms
12.3 - training  | batch=4, size=256x256: 4386 ± 108 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1481 ± 101 ms
13.2 - training  | batch=1, size=128x128: 2103 ± 76 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1678 ± 90 ms
14.2 - training  | batch=10, size=1024x1536: 3888 ± 63 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7739 ± 175 ms
15.2 - training  | batch=1, size=512x512: 4735 ± 196 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2336 ± 125 ms
16.2 - training  | batch=1, size=384x384: 6424 ± 185 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5638 ± 115 ms
17.2 - training  | batch=10, size=64x64: 10370.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12555 ± 256 ms
18.2 - training  | batch=10, size=1024x300: 8408 ± 246 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1442 ± 133 ms

Device Inference Score: 722
Device Training Score: 669
Device AI Score: 1391

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 276 ± 70 ms
1.2 - training  | batch=50, size=224x224: 3842 ± 159 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 676 ± 89 ms
2.2 - training  | batch=20, size=346x346: 4912 ± 193 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 674 ± 87 ms
3.2 - training  | batch=10, size=346x346: 5972 ± 278 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1065 ± 115 ms
4.2 - training  | batch=8, size=346x346: 10582 ± 353 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 564 ± 103 ms
5.2 - training  | batch=10, size=346x346: 3672 ± 125 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 862 ± 91 ms
6.2 - training  | batch=10, size=256x256: 9068 ± 459 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1222 ± 49 ms
7.2 - training  | batch=2, size=224x224: 850 ± 87 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1301 ± 39 ms
8.2 - inference | batch=1, size=1536x1536: 1218 ± 37 ms
8.3 - training  | batch=10, size=512x512: 3386 ± 68 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1433 ± 36 ms
9.2 - inference | batch=1, size=1024x1024: 2282 ± 48 ms
9.3 - training  | batch=10, size=224x224: 3688 ± 86 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3164 ± 75 ms
10.2 - inference | batch=1, size=1536x1536: 2906 ± 88 ms
10.3 - training  | batch=5, size=512x512: 4500 ± 94 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3124 ± 51 ms
11.2 - inference | batch=1, size=1024x1024: 5022 ± 66 ms
11.3 - training  | batch=15, size=128x128: 3811 ± 162 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5255 ± 81 ms
12.2 - inference | batch=1, size=1024x1024: 5402 ± 165 ms
12.3 - training  | batch=4, size=256x256: 4454 ± 120 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1525 ± 69 ms
13.2 - training  | batch=1, size=128x128: 1982 ± 98 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1409 ± 92 ms
14.2 - training  | batch=10, size=1024x1536: 3527 ± 44 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 5056 ± 32 ms
15.2 - training  | batch=1, size=512x512: 2948 ± 785 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 1768 ± 140 ms
16.2 - training  | batch=1, size=384x384: 1672 ± 97 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5487 ± 220 ms
17.2 - training  | batch=10, size=64x64: 10064.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11726 ± 521 ms
18.2 - training  | batch=10, size=1024x300: 8113 ± 61 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1462 ± 106 ms

Device Inference Score: 755
Device Training Score: 731
Device AI Score: 1486

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 167 ± 14 ms
1.2 - training  | batch=50, size=224x224: 1180 ± 604 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 479 ± 70 ms
2.2 - training  | batch=20, size=346x346: 1836 ± 145 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 518 ± 82 ms
3.2 - training  | batch=10, size=346x346: 4022 ± 2354 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 998 ± 99 ms
4.2 - training  | batch=8, size=346x346: 10461 ± 646 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 505 ± 73 ms
5.2 - training  | batch=10, size=346x346: 3333 ± 736 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 712 ± 82 ms
6.2 - training  | batch=10, size=256x256: 5933 ± 1319 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 632 ± 4 ms
7.2 - training  | batch=2, size=224x224: 810 ± 84 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 774 ± 9 ms
8.2 - inference | batch=1, size=1536x1536: 729 ± 24 ms
8.3 - training  | batch=10, size=512x512: 2893 ± 85 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 681 ± 4 ms
9.2 - inference | batch=1, size=1024x1024: 1183 ± 2 ms
9.3 - training  | batch=10, size=224x224: 3602 ± 74 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 2349 ± 12 ms
10.2 - inference | batch=1, size=1536x1536: 2137 ± 24 ms
10.3 - training  | batch=5, size=512x512: 4153 ± 131 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 2217 ± 42 ms
11.2 - inference | batch=1, size=1024x1024: 3589 ± 52 ms
11.3 - training  | batch=15, size=128x128: 3781 ± 88 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 4613 ± 87 ms
12.2 - inference | batch=1, size=1024x1024: 4801 ± 89 ms
12.3 - training  | batch=4, size=256x256: 4235 ± 101 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1449 ± 95 ms
13.2 - training  | batch=1, size=128x128: 1984 ± 73 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1696 ± 101 ms
14.2 - training  | batch=10, size=1024x1536: 3868 ± 116 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7604 ± 88 ms
15.2 - training  | batch=1, size=512x512: 4114 ± 354 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2331 ± 82 ms
16.2 - training  | batch=1, size=384x384: 5812 ± 640 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5530 ± 108 ms
17.2 - training  | batch=10, size=64x64: 9890.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11519 ± 462 ms
18.2 - training  | batch=10, size=1024x300: 8333 ± 69 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1523 ± 108 ms

Device Inference Score: 939
Device Training Score: 807
Device AI Score: 1746

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 295 ± 68 ms
1.2 - training  | batch=50, size=224x224: 3941 ± 101 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 674 ± 89 ms
2.2 - training  | batch=20, size=346x346: 4996 ± 139 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 719 ± 92 ms
3.2 - training  | batch=10, size=346x346: 7103 ± 189 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1106 ± 103 ms
4.2 - training  | batch=8, size=346x346: 10592 ± 670 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 580 ± 100 ms
5.2 - training  | batch=10, size=346x346: 3809 ± 327 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 893 ± 109 ms
6.2 - training  | batch=10, size=256x256: 9382 ± 342 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1221 ± 45 ms
7.2 - training  | batch=2, size=224x224: 821 ± 70 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1301 ± 29 ms
8.2 - inference | batch=1, size=1536x1536: 1238 ± 38 ms
8.3 - training  | batch=10, size=512x512: 3310 ± 58 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1407 ± 48 ms
9.2 - inference | batch=1, size=1024x1024: 2192 ± 20 ms
9.3 - training  | batch=10, size=224x224: 3714 ± 31 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3289 ± 115 ms
10.2 - inference | batch=1, size=1536x1536: 3001 ± 94 ms
10.3 - training  | batch=5, size=512x512: 4526 ± 173 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3166 ± 79 ms
11.2 - inference | batch=1, size=1024x1024: 5135 ± 68 ms
11.3 - training  | batch=15, size=128x128: 3926 ± 94 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5438 ± 125 ms
12.2 - inference | batch=1, size=1024x1024: 5618 ± 88 ms
12.3 - training  | batch=4, size=256x256: 4386 ± 46 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1496 ± 91 ms
13.2 - training  | batch=1, size=128x128: 2025 ± 79 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1653 ± 84 ms
14.2 - training  | batch=10, size=1024x1536: 3948 ± 82 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7536 ± 118 ms
15.2 - training  | batch=1, size=512x512: 4579 ± 349 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2352 ± 96 ms
16.2 - training  | batch=1, size=384x384: 3731 ± 166 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5633 ± 182 ms
17.2 - training  | batch=10, size=64x64: 10511.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11442 ± 376 ms
18.2 - training  | batch=10, size=1024x300: 8364 ± 79 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1522 ± 127 ms

Device Inference Score: 717
Device Training Score: 665
Device AI Score: 1382

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 290 ± 69 ms
1.2 - training  | batch=50, size=224x224: 4124 ± 172 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 687 ± 86 ms
2.2 - training  | batch=20, size=346x346: 4930 ± 86 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 681 ± 88 ms
3.2 - training  | batch=10, size=346x346: 6812 ± 280 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1055 ± 115 ms
4.2 - training  | batch=8, size=346x346: 9928 ± 301 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 541 ± 89 ms
5.2 - training  | batch=10, size=346x346: 3906 ± 308 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 891 ± 105 ms
6.2 - training  | batch=10, size=256x256: 9280 ± 349 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1241 ± 46 ms
7.2 - training  | batch=2, size=224x224: 850 ± 90 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1324 ± 42 ms
8.2 - inference | batch=1, size=1536x1536: 1200 ± 54 ms
8.3 - training  | batch=10, size=512x512: 3298 ± 67 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1408 ± 57 ms
9.2 - inference | batch=1, size=1024x1024: 2249 ± 44 ms
9.3 - training  | batch=10, size=224x224: 3696 ± 49 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3192 ± 65 ms
10.2 - inference | batch=1, size=1536x1536: 2940 ± 110 ms
10.3 - training  | batch=5, size=512x512: 4486 ± 226 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3088 ± 69 ms
11.2 - inference | batch=1, size=1024x1024: 4984 ± 124 ms
11.3 - training  | batch=15, size=128x128: 3902 ± 34 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5286 ± 96 ms
12.2 - inference | batch=1, size=1024x1024: 5439 ± 89 ms
12.3 - training  | batch=4, size=256x256: 4466 ± 167 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1439 ± 97 ms
13.2 - training  | batch=1, size=128x128: 1971 ± 100 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1642 ± 94 ms
14.2 - training  | batch=10, size=1024x1536: 3878 ± 108 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7652 ± 58 ms
15.2 - training  | batch=1, size=512x512: 4683 ± 95 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2306 ± 92 ms
16.2 - training  | batch=1, size=384x384: 5849 ± 89 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5538 ± 184 ms
17.2 - training  | batch=10, size=64x64: 9707.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11320 ± 135 ms
18.2 - training  | batch=10, size=1024x300: 8313 ± 209 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1522 ± 108 ms

Device Inference Score: 728
Device Training Score: 654
Device AI Score: 1382

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 263 ± 59 ms
1.2 - training  | batch=50, size=224x224: 3982 ± 88 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 683 ± 88 ms
2.2 - training  | batch=20, size=346x346: 5171 ± 186 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 704 ± 93 ms
3.2 - training  | batch=10, size=346x346: 5954 ± 397 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1116 ± 220 ms
4.2 - training  | batch=8, size=346x346: 10624 ± 433 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 575 ± 101 ms
5.2 - training  | batch=10, size=346x346: 3800 ± 96 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 902 ± 107 ms
6.2 - training  | batch=10, size=256x256: 7892 ± 698 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1215 ± 48 ms
7.2 - training  | batch=2, size=224x224: 807 ± 96 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1274 ± 28 ms
8.2 - inference | batch=1, size=1536x1536: 1189 ± 42 ms
8.3 - training  | batch=10, size=512x512: 3314 ± 37 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1394 ± 59 ms
9.2 - inference | batch=1, size=1024x1024: 2245 ± 51 ms
9.3 - training  | batch=10, size=224x224: 3758 ± 51 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3301 ± 66 ms
10.2 - inference | batch=1, size=1536x1536: 3052 ± 76 ms
10.3 - training  | batch=5, size=512x512: 4448 ± 77 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3189 ± 49 ms
11.2 - inference | batch=1, size=1024x1024: 5151 ± 94 ms
11.3 - training  | batch=15, size=128x128: 3895 ± 119 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5314 ± 91 ms
12.2 - inference | batch=1, size=1024x1024: 5706 ± 88 ms
12.3 - training  | batch=4, size=256x256: 4381 ± 80 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1513 ± 98 ms
13.2 - training  | batch=1, size=128x128: 1992 ± 84 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1632 ± 66 ms
14.2 - training  | batch=10, size=1024x1536: 3860 ± 89 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7695 ± 99 ms
15.2 - training  | batch=1, size=512x512: 4901 ± 168 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2334 ± 121 ms
16.2 - training  | batch=1, size=384x384: 6133 ± 204 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5248 ± 115 ms
17.2 - training  | batch=10, size=64x64: 10457.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11215 ± 59 ms
18.2 - training  | batch=10, size=1024x300: 8191 ± 183 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1580 ± 189 ms

Device Inference Score: 722
Device Training Score: 659
Device AI Score: 1381

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 266 ± 60 ms
1.2 - training  | batch=50, size=224x224: 3963 ± 112 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 688 ± 89 ms
2.2 - training  | batch=20, size=346x346: 5148 ± 217 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 686 ± 90 ms
3.2 - training  | batch=10, size=346x346: 6917 ± 327 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1105 ± 114 ms
4.2 - training  | batch=8, size=346x346: 11435 ± 306 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 554 ± 75 ms
5.2 - training  | batch=10, size=346x346: 3603 ± 246 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 892 ± 103 ms
6.2 - training  | batch=10, size=256x256: 8492 ± 775 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1218 ± 45 ms
7.2 - training  | batch=2, size=224x224: 844 ± 94 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1269 ± 53 ms
8.2 - inference | batch=1, size=1536x1536: 1211 ± 39 ms
8.3 - training  | batch=10, size=512x512: 3271 ± 86 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1457 ± 57 ms
9.2 - inference | batch=1, size=1024x1024: 2327 ± 48 ms
9.3 - training  | batch=10, size=224x224: 3685 ± 30 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3192 ± 78 ms
10.2 - inference | batch=1, size=1536x1536: 2897 ± 100 ms
10.3 - training  | batch=5, size=512x512: 4596 ± 97 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3086 ± 48 ms
11.2 - inference | batch=1, size=1024x1024: 4939 ± 77 ms
11.3 - training  | batch=15, size=128x128: 3783 ± 96 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5352 ± 107 ms
12.2 - inference | batch=1, size=1024x1024: 5425 ± 117 ms
12.3 - training  | batch=4, size=256x256: 4463 ± 100 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1492 ± 93 ms
13.2 - training  | batch=1, size=128x128: 2041 ± 34 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1655 ± 98 ms
14.2 - training  | batch=10, size=1024x1536: 3881 ± 49 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7498 ± 75 ms
15.2 - training  | batch=1, size=512x512: 4994 ± 261 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2289 ± 74 ms
16.2 - training  | batch=1, size=384x384: 5924 ± 170 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5622 ± 139 ms
17.2 - training  | batch=10, size=64x64: 12741.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12019 ± 267 ms
18.2 - training  | batch=10, size=1024x300: 8148 ± 108 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1467 ± 167 ms

Device Inference Score: 727
Device Training Score: 642
Device AI Score: 1369

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 255 ± 60 ms
1.2 - training  | batch=50, size=224x224: 3806 ± 294 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 680 ± 91 ms
2.2 - training  | batch=20, size=346x346: 4839 ± 258 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 680 ± 101 ms
3.2 - training  | batch=10, size=346x346: 6996 ± 755 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1049 ± 105 ms
4.2 - training  | batch=8, size=346x346: 8724 ± 1065 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 571 ± 85 ms
5.2 - training  | batch=10, size=346x346: 3628 ± 264 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 899 ± 98 ms
6.2 - training  | batch=10, size=256x256: 9047 ± 595 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1190 ± 41 ms
7.2 - training  | batch=2, size=224x224: 855 ± 95 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1286 ± 42 ms
8.2 - inference | batch=1, size=1536x1536: 1197 ± 34 ms
8.3 - training  | batch=10, size=512x512: 3261 ± 27 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1354 ± 36 ms
9.2 - inference | batch=1, size=1024x1024: 2167 ± 30 ms
9.3 - training  | batch=10, size=224x224: 3710 ± 58 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3265 ± 76 ms
10.2 - inference | batch=1, size=1536x1536: 3048 ± 72 ms
10.3 - training  | batch=5, size=512x512: 4537 ± 76 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3198 ± 53 ms
11.2 - inference | batch=1, size=1024x1024: 5053 ± 45 ms
11.3 - training  | batch=15, size=128x128: 3955 ± 149 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5306 ± 87 ms
12.2 - inference | batch=1, size=1024x1024: 5549 ± 86 ms
12.3 - training  | batch=4, size=256x256: 4345 ± 103 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1444 ± 87 ms
13.2 - training  | batch=1, size=128x128: 2046 ± 70 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1658 ± 86 ms
14.2 - training  | batch=10, size=1024x1536: 3905 ± 92 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7554 ± 71 ms
15.2 - training  | batch=1, size=512x512: 4605 ± 537 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2368 ± 74 ms
16.2 - training  | batch=1, size=384x384: 5420 ± 474 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5593 ± 117 ms
17.2 - training  | batch=10, size=64x64: 99222.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11574 ± 121 ms
18.2 - training  | batch=10, size=1024x300: 8248 ± 122 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1570 ± 207 ms

Device Inference Score: 729
Device Training Score: 586
Device AI Score: 1315

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 235 ± 45 ms
1.2 - training  | batch=50, size=224x224: 3794 ± 264 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 661 ± 88 ms
2.2 - training  | batch=20, size=346x346: 4649 ± 185 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 695 ± 85 ms
3.2 - training  | batch=10, size=346x346: 6875 ± 154 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1026 ± 105 ms
4.2 - training  | batch=8, size=346x346: 10396 ± 578 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 573 ± 103 ms
5.2 - training  | batch=10, size=346x346: 3862 ± 115 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 905 ± 92 ms
6.2 - training  | batch=10, size=256x256: 9456 ± 314 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1252 ± 49 ms
7.2 - training  | batch=2, size=224x224: 851 ± 94 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1287 ± 70 ms
8.2 - inference | batch=1, size=1536x1536: 1224 ± 46 ms
8.3 - training  | batch=10, size=512x512: 3315 ± 54 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1435 ± 49 ms
9.2 - inference | batch=1, size=1024x1024: 2287 ± 57 ms
9.3 - training  | batch=10, size=224x224: 3712 ± 69 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3228 ± 119 ms
10.2 - inference | batch=1, size=1536x1536: 2957 ± 88 ms
10.3 - training  | batch=5, size=512x512: 4511 ± 139 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3125 ± 43 ms
11.2 - inference | batch=1, size=1024x1024: 4823 ± 65 ms
11.3 - training  | batch=15, size=128x128: 3913 ± 87 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5287 ± 124 ms
12.2 - inference | batch=1, size=1024x1024: 5473 ± 86 ms
12.3 - training  | batch=4, size=256x256: 4481 ± 79 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1464 ± 89 ms
13.2 - training  | batch=1, size=128x128: 2030 ± 94 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1634 ± 90 ms
14.2 - training  | batch=10, size=1024x1536: 3876 ± 124 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7615 ± 28 ms
15.2 - training  | batch=1, size=512x512: 4540 ± 359 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2302 ± 108 ms
16.2 - training  | batch=1, size=384x384: 4458 ± 636 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5496 ± 88 ms
17.2 - training  | batch=10, size=64x64: 10055.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12594 ± 178 ms
18.2 - training  | batch=10, size=1024x300: 8397 ± 248 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1459 ± 99 ms

Device Inference Score: 731
Device Training Score: 664
Device AI Score: 1395

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 295 ± 74 ms
1.2 - training  | batch=50, size=224x224: 3593 ± 208 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 693 ± 88 ms
2.2 - training  | batch=20, size=346x346: 4752 ± 168 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 691 ± 95 ms
3.2 - training  | batch=10, size=346x346: 6048 ± 1063 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1014 ± 125 ms
4.2 - training  | batch=8, size=346x346: 10052 ± 182 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 543 ± 100 ms
5.2 - training  | batch=10, size=346x346: 3559 ± 442 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 888 ± 101 ms
6.2 - training  | batch=10, size=256x256: 8605 ± 743 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1232 ± 47 ms
7.2 - training  | batch=2, size=224x224: 837 ± 78 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1334 ± 45 ms
8.2 - inference | batch=1, size=1536x1536: 1214 ± 28 ms
8.3 - training  | batch=10, size=512x512: 3355 ± 99 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1363 ± 56 ms
9.2 - inference | batch=1, size=1024x1024: 2211 ± 53 ms
9.3 - training  | batch=10, size=224x224: 3611 ± 44 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3331 ± 131 ms
10.2 - inference | batch=1, size=1536x1536: 3061 ± 69 ms
10.3 - training  | batch=5, size=512x512: 4661 ± 97 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3188 ± 49 ms
11.2 - inference | batch=1, size=1024x1024: 5044 ± 108 ms
11.3 - training  | batch=15, size=128x128: 3959 ± 89 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5422 ± 41 ms
12.2 - inference | batch=1, size=1024x1024: 5464 ± 108 ms
12.3 - training  | batch=4, size=256x256: 4421 ± 34 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1504 ± 73 ms
13.2 - training  | batch=1, size=128x128: 1987 ± 73 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1693 ± 92 ms
14.2 - training  | batch=10, size=1024x1536: 3880 ± 106 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7681 ± 184 ms
15.2 - training  | batch=1, size=512x512: 5118 ± 66 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2339 ± 73 ms
16.2 - training  | batch=1, size=384x384: 5926 ± 279 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5721 ± 99 ms
17.2 - training  | batch=10, size=64x64: 9963.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12466 ± 163 ms
18.2 - training  | batch=10, size=1024x300: 8355 ± 110 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1464 ± 114 ms

Device Inference Score: 719
Device Training Score: 664
Device AI Score: 1383

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 288 ± 70 ms
1.2 - training  | batch=50, size=224x224: 4049 ± 138 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 661 ± 100 ms
2.2 - training  | batch=20, size=346x346: 4629 ± 276 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 692 ± 95 ms
3.2 - training  | batch=10, size=346x346: 7306 ± 369 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1140 ± 121 ms
4.2 - training  | batch=8, size=346x346: 10041 ± 123 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 565 ± 98 ms
5.2 - training  | batch=10, size=346x346: 3695 ± 197 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 898 ± 105 ms
6.2 - training  | batch=10, size=256x256: 9439 ± 206 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1234 ± 45 ms
7.2 - training  | batch=2, size=224x224: 836 ± 76 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1321 ± 32 ms
8.2 - inference | batch=1, size=1536x1536: 1224 ± 40 ms
8.3 - training  | batch=10, size=512x512: 3326 ± 73 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1373 ± 52 ms
9.2 - inference | batch=1, size=1024x1024: 2211 ± 17 ms
9.3 - training  | batch=10, size=224x224: 3682 ± 61 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3254 ± 87 ms
10.2 - inference | batch=1, size=1536x1536: 3012 ± 87 ms
10.3 - training  | batch=5, size=512x512: 4495 ± 60 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3148 ± 50 ms
11.2 - inference | batch=1, size=1024x1024: 5067 ± 103 ms
11.3 - training  | batch=15, size=128x128: 3999 ± 116 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5372 ± 108 ms
12.2 - inference | batch=1, size=1024x1024: 5594 ± 117 ms
12.3 - training  | batch=4, size=256x256: 4270 ± 130 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1535 ± 77 ms
13.2 - training  | batch=1, size=128x128: 1958 ± 107 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1647 ± 98 ms
14.2 - training  | batch=10, size=1024x1536: 3960 ± 68 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7482 ± 166 ms
15.2 - training  | batch=1, size=512x512: 4892 ± 305 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2324 ± 96 ms
16.2 - training  | batch=1, size=384x384: 5755 ± 512 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5385 ± 189 ms
17.2 - training  | batch=10, size=64x64: 11517.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12136 ± 105 ms
18.2 - training  | batch=10, size=1024x300: 7970 ± 71 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1492 ± 92 ms

Device Inference Score: 720
Device Training Score: 650
Device AI Score: 1370

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 252 ± 55 ms
1.2 - training  | batch=50, size=224x224: 3804 ± 170 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 659 ± 89 ms
2.2 - training  | batch=20, size=346x346: 4688 ± 301 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 672 ± 98 ms
3.2 - training  | batch=10, size=346x346: 6333 ± 461 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1065 ± 114 ms
4.2 - training  | batch=8, size=346x346: 10726 ± 159 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 571 ± 83 ms
5.2 - training  | batch=10, size=346x346: 3826 ± 173 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 925 ± 96 ms
6.2 - training  | batch=10, size=256x256: 9396 ± 115 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1257 ± 52 ms
7.2 - training  | batch=2, size=224x224: 833 ± 88 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1305 ± 37 ms
8.2 - inference | batch=1, size=1536x1536: 1222 ± 36 ms
8.3 - training  | batch=10, size=512x512: 3324 ± 87 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1466 ± 55 ms
9.2 - inference | batch=1, size=1024x1024: 2253 ± 46 ms
9.3 - training  | batch=10, size=224x224: 3701 ± 67 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3330 ± 123 ms
10.2 - inference | batch=1, size=1536x1536: 3012 ± 77 ms
10.3 - training  | batch=5, size=512x512: 4585 ± 147 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3137 ± 38 ms
11.2 - inference | batch=1, size=1024x1024: 4857 ± 77 ms
11.3 - training  | batch=15, size=128x128: 3911 ± 139 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5279 ± 143 ms
12.2 - inference | batch=1, size=1024x1024: 5626 ± 157 ms
12.3 - training  | batch=4, size=256x256: 4545 ± 39 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1518 ± 108 ms
13.2 - training  | batch=1, size=128x128: 2096 ± 57 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1712 ± 84 ms
14.2 - training  | batch=10, size=1024x1536: 3828 ± 95 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7660 ± 123 ms
15.2 - training  | batch=1, size=512x512: 5210 ± 103 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2328 ± 89 ms
16.2 - training  | batch=1, size=384x384: 6230 ± 278 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5468 ± 102 ms
17.2 - training  | batch=10, size=64x64: 10277.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11253 ± 50 ms
18.2 - training  | batch=10, size=1024x300: 8246 ± 190 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1509 ± 164 ms

Device Inference Score: 724
Device Training Score: 648
Device AI Score: 1372

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 255 ± 50 ms
1.2 - training  | batch=50, size=224x224: 3679 ± 298 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 658 ± 91 ms
2.2 - training  | batch=20, size=346x346: 4137 ± 432 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 671 ± 91 ms
3.2 - training  | batch=10, size=346x346: 6713 ± 509 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1048 ± 110 ms
4.2 - training  | batch=8, size=346x346: 10670 ± 871 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 547 ± 90 ms
5.2 - training  | batch=10, size=346x346: 4070 ± 102 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 933 ± 102 ms
6.2 - training  | batch=10, size=256x256: 9664 ± 451 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1241 ± 58 ms
7.2 - training  | batch=2, size=224x224: 835 ± 93 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1315 ± 39 ms
8.2 - inference | batch=1, size=1536x1536: 1209 ± 38 ms
8.3 - training  | batch=10, size=512x512: 3345 ± 73 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1444 ± 53 ms
9.2 - inference | batch=1, size=1024x1024: 2249 ± 58 ms
9.3 - training  | batch=10, size=224x224: 3664 ± 69 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3280 ± 128 ms
10.2 - inference | batch=1, size=1536x1536: 2926 ± 83 ms
10.3 - training  | batch=5, size=512x512: 4571 ± 47 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3036 ± 41 ms
11.2 - inference | batch=1, size=1024x1024: 4836 ± 15 ms
11.3 - training  | batch=15, size=128x128: 3897 ± 110 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5358 ± 144 ms
12.2 - inference | batch=1, size=1024x1024: 5599 ± 212 ms
12.3 - training  | batch=4, size=256x256: 4536 ± 130 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1491 ± 97 ms
13.2 - training  | batch=1, size=128x128: 2022 ± 74 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1651 ± 81 ms
14.2 - training  | batch=10, size=1024x1536: 3942 ± 90 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7689 ± 136 ms
15.2 - training  | batch=1, size=512x512: 4023 ± 474 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2384 ± 66 ms
16.2 - training  | batch=1, size=384x384: 5002 ± 725 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5472 ± 87 ms
17.2 - training  | batch=10, size=64x64: 10042.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11794 ± 209 ms
18.2 - training  | batch=10, size=1024x300: 8273 ± 41 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1492 ± 95 ms

Device Inference Score: 729
Device Training Score: 667
Device AI Score: 1396

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 168 ± 13 ms
1.2 - training  | batch=50, size=224x224: 1090 ± 516 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 496 ± 74 ms
2.2 - training  | batch=20, size=346x346: 1897 ± 141 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 583 ± 82 ms
3.2 - training  | batch=10, size=346x346: 2606 ± 914 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 930 ± 106 ms
4.2 - training  | batch=8, size=346x346: 4345 ± 970 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 513 ± 68 ms
5.2 - training  | batch=10, size=346x346: 2609 ± 990 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 688 ± 59 ms
6.2 - training  | batch=10, size=256x256: 5862 ± 2291 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 632 ± 5 ms
7.2 - training  | batch=2, size=224x224: 819 ± 97 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 763 ± 13 ms
8.2 - inference | batch=1, size=1536x1536: 722 ± 21 ms
8.3 - training  | batch=10, size=512x512: 2941 ± 78 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 685 ± 4 ms
9.2 - inference | batch=1, size=1024x1024: 1180 ± 11 ms
9.3 - training  | batch=10, size=224x224: 3605 ± 96 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 2397 ± 17 ms
10.2 - inference | batch=1, size=1536x1536: 2183 ± 17 ms
10.3 - training  | batch=5, size=512x512: 4153 ± 54 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 2070 ± 62 ms
11.2 - inference | batch=1, size=1024x1024: 3594 ± 52 ms
11.3 - training  | batch=15, size=128x128: 3813 ± 89 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 4659 ± 89 ms
12.2 - inference | batch=1, size=1024x1024: 4918 ± 53 ms
12.3 - training  | batch=4, size=256x256: 4280 ± 60 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1453 ± 92 ms
13.2 - training  | batch=1, size=128x128: 1957 ± 83 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1626 ± 90 ms
14.2 - training  | batch=10, size=1024x1536: 3871 ± 91 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7656 ± 153 ms
15.2 - training  | batch=1, size=512x512: 5002 ± 175 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2327 ± 62 ms
16.2 - training  | batch=1, size=384x384: 6465 ± 241 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5361 ± 38 ms
17.2 - training  | batch=10, size=64x64: 10335.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11556 ± 423 ms
18.2 - training  | batch=10, size=1024x300: 8296 ± 277 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1546 ± 145 ms

Device Inference Score: 939
Device Training Score: 865
Device AI Score: 1804

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 255 ± 56 ms
1.2 - training  | batch=50, size=224x224: 3626 ± 173 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 661 ± 85 ms
2.2 - training  | batch=20, size=346x346: 4563 ± 378 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 683 ± 91 ms
3.2 - training  | batch=10, size=346x346: 6146 ± 497 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1043 ± 109 ms
4.2 - training  | batch=8, size=346x346: 8253 ± 2199 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 568 ± 72 ms
5.2 - training  | batch=10, size=346x346: 3902 ± 161 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 897 ± 95 ms
6.2 - training  | batch=10, size=256x256: 8864 ± 344 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1240 ± 48 ms
7.2 - training  | batch=2, size=224x224: 868 ± 97 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1327 ± 44 ms
8.2 - inference | batch=1, size=1536x1536: 1206 ± 44 ms
8.3 - training  | batch=10, size=512x512: 3361 ± 74 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1432 ± 52 ms
9.2 - inference | batch=1, size=1024x1024: 2226 ± 23 ms
9.3 - training  | batch=10, size=224x224: 3719 ± 25 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3196 ± 104 ms
10.2 - inference | batch=1, size=1536x1536: 2932 ± 104 ms
10.3 - training  | batch=5, size=512x512: 4658 ± 122 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 2979 ± 27 ms
11.2 - inference | batch=1, size=1024x1024: 4815 ± 71 ms
11.3 - training  | batch=15, size=128x128: 3916 ± 134 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5246 ± 108 ms
12.2 - inference | batch=1, size=1024x1024: 5546 ± 160 ms
12.3 - training  | batch=4, size=256x256: 4491 ± 49 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1479 ± 72 ms
13.2 - training  | batch=1, size=128x128: 2014 ± 79 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1445 ± 90 ms
14.2 - training  | batch=10, size=1024x1536: 3468 ± 82 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 5073 ± 29 ms
15.2 - training  | batch=1, size=512x512: 2930 ± 702 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 1838 ± 143 ms
16.2 - training  | batch=1, size=384x384: 1634 ± 85 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5368 ± 113 ms
17.2 - training  | batch=10, size=64x64: 9266.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11841 ± 443 ms
18.2 - training  | batch=10, size=1024x300: 8104 ± 242 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1472 ± 88 ms

Device Inference Score: 757
Device Training Score: 745
Device AI Score: 1502

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 166 ± 13 ms
1.2 - training  | batch=50, size=224x224: 1011 ± 455 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 498 ± 80 ms
2.2 - training  | batch=20, size=346x346: 1781 ± 110 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 543 ± 85 ms
3.2 - training  | batch=10, size=346x346: 4774 ± 2376 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1057 ± 112 ms
4.2 - training  | batch=8, size=346x346: 9275 ± 438 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 493 ± 72 ms
5.2 - training  | batch=10, size=346x346: 3754 ± 228 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 704 ± 77 ms
6.2 - training  | batch=10, size=256x256: 6363 ± 2405 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 632 ± 7 ms
7.2 - training  | batch=2, size=224x224: 788 ± 78 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 760 ± 12 ms
8.2 - inference | batch=1, size=1536x1536: 700 ± 7 ms
8.3 - training  | batch=10, size=512x512: 2916 ± 50 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 684 ± 5 ms
9.2 - inference | batch=1, size=1024x1024: 1186 ± 11 ms
9.3 - training  | batch=10, size=224x224: 3485 ± 105 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 2384 ± 12 ms
10.2 - inference | batch=1, size=1536x1536: 2160 ± 13 ms
10.3 - training  | batch=5, size=512x512: 4164 ± 187 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 2165 ± 60 ms
11.2 - inference | batch=1, size=1024x1024: 3628 ± 33 ms
11.3 - training  | batch=15, size=128x128: 3819 ± 75 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 4624 ± 53 ms
12.2 - inference | batch=1, size=1024x1024: 4904 ± 84 ms
12.3 - training  | batch=4, size=256x256: 4325 ± 92 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1462 ± 83 ms
13.2 - training  | batch=1, size=128x128: 2000 ± 101 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1637 ± 95 ms
14.2 - training  | batch=10, size=1024x1536: 3939 ± 105 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7646 ± 27 ms
15.2 - training  | batch=1, size=512x512: 5113 ± 60 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2353 ± 115 ms
16.2 - training  | batch=1, size=384x384: 5512 ± 798 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5598 ± 203 ms
17.2 - training  | batch=10, size=64x64: 10055.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12114 ± 222 ms
18.2 - training  | batch=10, size=1024x300: 8139 ± 204 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1454 ± 125 ms

Device Inference Score: 936
Device Training Score: 797
Device AI Score: 1733

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 307 ± 75 ms
1.2 - training  | batch=50, size=224x224: 4001 ± 33 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 667 ± 85 ms
2.2 - training  | batch=20, size=346x346: 4527 ± 213 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 686 ± 98 ms
3.2 - training  | batch=10, size=346x346: 6474 ± 620 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1070 ± 89 ms
4.2 - training  | batch=8, size=346x346: 10523 ± 593 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 540 ± 82 ms
5.2 - training  | batch=10, size=346x346: 3771 ± 235 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 889 ± 108 ms
6.2 - training  | batch=10, size=256x256: 8661 ± 250 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1226 ± 48 ms
7.2 - training  | batch=2, size=224x224: 847 ± 79 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1312 ± 45 ms
8.2 - inference | batch=1, size=1536x1536: 1223 ± 47 ms
8.3 - training  | batch=10, size=512x512: 3347 ± 103 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1389 ± 57 ms
9.2 - inference | batch=1, size=1024x1024: 2233 ± 64 ms
9.3 - training  | batch=10, size=224x224: 3798 ± 50 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3356 ± 76 ms
10.2 - inference | batch=1, size=1536x1536: 3001 ± 71 ms
10.3 - training  | batch=5, size=512x512: 4476 ± 134 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3226 ± 67 ms
11.2 - inference | batch=1, size=1024x1024: 4994 ± 69 ms
11.3 - training  | batch=15, size=128x128: 3977 ± 78 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5321 ± 69 ms
12.2 - inference | batch=1, size=1024x1024: 5532 ± 110 ms
12.3 - training  | batch=4, size=256x256: 4511 ± 125 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1507 ± 82 ms
13.2 - training  | batch=1, size=128x128: 2018 ± 93 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1660 ± 61 ms
14.2 - training  | batch=10, size=1024x1536: 3897 ± 98 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7538 ± 102 ms
15.2 - training  | batch=1, size=512x512: 4730 ± 540 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2273 ± 65 ms
16.2 - training  | batch=1, size=384x384: 5581 ± 587 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5415 ± 108 ms
17.2 - training  | batch=10, size=64x64: 9783.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 12186 ± 96 ms
18.2 - training  | batch=10, size=1024x300: 8129 ± 259 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1438 ± 165 ms

Device Inference Score: 723
Device Training Score: 660
Device AI Score: 1383

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 259 ± 62 ms
1.2 - training  | batch=50, size=224x224: 3983 ± 283 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 693 ± 87 ms
2.2 - training  | batch=20, size=346x346: 4942 ± 88 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 698 ± 87 ms
3.2 - training  | batch=10, size=346x346: 6579 ± 187 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1046 ± 109 ms
4.2 - training  | batch=8, size=346x346: 9869 ± 96 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 569 ± 96 ms
5.2 - training  | batch=10, size=346x346: 3682 ± 262 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 913 ± 99 ms
6.2 - training  | batch=10, size=256x256: 9177 ± 138 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1249 ± 46 ms
7.2 - training  | batch=2, size=224x224: 845 ± 90 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1301 ± 30 ms
8.2 - inference | batch=1, size=1536x1536: 1222 ± 47 ms
8.3 - training  | batch=10, size=512x512: 3332 ± 59 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1441 ± 32 ms
9.2 - inference | batch=1, size=1024x1024: 2363 ± 36 ms
9.3 - training  | batch=10, size=224x224: 3739 ± 38 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3187 ± 86 ms
10.2 - inference | batch=1, size=1536x1536: 2984 ± 89 ms
10.3 - training  | batch=5, size=512x512: 4459 ± 159 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3074 ± 55 ms
11.2 - inference | batch=1, size=1024x1024: 4924 ± 104 ms
11.3 - training  | batch=15, size=128x128: 3902 ± 56 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5306 ± 63 ms
12.2 - inference | batch=1, size=1024x1024: 5559 ± 126 ms
12.3 - training  | batch=4, size=256x256: 4512 ± 112 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1510 ± 109 ms
13.2 - training  | batch=1, size=128x128: 1986 ± 80 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1662 ± 69 ms
14.2 - training  | batch=10, size=1024x1536: 3956 ± 87 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7518 ± 47 ms
15.2 - training  | batch=1, size=512x512: 4632 ± 432 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2324 ± 100 ms
16.2 - training  | batch=1, size=384x384: 4606 ± 318 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5532 ± 143 ms
17.2 - training  | batch=10, size=64x64: 10068.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11612 ± 519 ms
18.2 - training  | batch=10, size=1024x300: 8374 ± 131 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1699 ± 195 ms

Device Inference Score: 720
Device Training Score: 665
Device AI Score: 1385

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 289 ± 71 ms
1.2 - training  | batch=50, size=224x224: 4030 ± 140 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 672 ± 84 ms
2.2 - training  | batch=20, size=346x346: 4669 ± 230 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 709 ± 105 ms
3.2 - training  | batch=10, size=346x346: 6483 ± 441 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1059 ± 123 ms
4.2 - training  | batch=8, size=346x346: 9687 ± 590 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 570 ± 103 ms
5.2 - training  | batch=10, size=346x346: 3390 ± 452 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 903 ± 103 ms
6.2 - training  | batch=10, size=256x256: 9425 ± 336 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1208 ± 30 ms
7.2 - training  | batch=2, size=224x224: 828 ± 83 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1302 ± 52 ms
8.2 - inference | batch=1, size=1536x1536: 1183 ± 32 ms
8.3 - training  | batch=10, size=512x512: 3373 ± 65 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1389 ± 46 ms
9.2 - inference | batch=1, size=1024x1024: 2172 ± 17 ms
9.3 - training  | batch=10, size=224x224: 3706 ± 35 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3276 ± 63 ms
10.2 - inference | batch=1, size=1536x1536: 3084 ± 127 ms
10.3 - training  | batch=5, size=512x512: 4508 ± 60 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 3220 ± 51 ms
11.2 - inference | batch=1, size=1024x1024: 5121 ± 69 ms
11.3 - training  | batch=15, size=128x128: 3959 ± 117 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5313 ± 79 ms
12.2 - inference | batch=1, size=1024x1024: 5631 ± 165 ms
12.3 - training  | batch=4, size=256x256: 4475 ± 113 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1481 ± 90 ms
13.2 - training  | batch=1, size=128x128: 1989 ± 141 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1444 ± 80 ms
14.2 - training  | batch=10, size=1024x1536: 3440 ± 63 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 5067 ± 65 ms
15.2 - training  | batch=1, size=512x512: 3030 ± 592 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 1832 ± 155 ms
16.2 - training  | batch=1, size=384x384: 1681 ± 134 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5495 ± 170 ms
17.2 - training  | batch=10, size=64x64: 9160.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11532 ± 214 ms
18.2 - training  | batch=10, size=1024x300: 8052 ± 341 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1654 ± 155 ms

Device Inference Score: 743
Device Training Score: 736
Device AI Score: 1479

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 174 ± 15 ms
1.2 - training  | batch=50, size=224x224: 1021 ± 247 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 484 ± 74 ms
2.2 - training  | batch=20, size=346x346: 2428 ± 1050 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 546 ± 84 ms
3.2 - training  | batch=10, size=346x346: 3298 ± 1780 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 1075 ± 102 ms
4.2 - training  | batch=8, size=346x346: 10528 ± 665 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 565 ± 96 ms
5.2 - training  | batch=10, size=346x346: 3817 ± 227 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 953 ± 114 ms
6.2 - training  | batch=10, size=256x256: 9296 ± 99 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 1214 ± 48 ms
7.2 - training  | batch=2, size=224x224: 833 ± 92 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 1319 ± 44 ms
8.2 - inference | batch=1, size=1536x1536: 1219 ± 56 ms
8.3 - training  | batch=10, size=512x512: 3363 ± 117 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 1384 ± 50 ms
9.2 - inference | batch=1, size=1024x1024: 2260 ± 49 ms
9.3 - training  | batch=10, size=224x224: 3589 ± 83 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 3235 ± 69 ms
10.2 - inference | batch=1, size=1536x1536: 2955 ± 108 ms
10.3 - training  | batch=5, size=512x512: 4498 ± 60 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 2999 ± 52 ms
11.2 - inference | batch=1, size=1024x1024: 4878 ± 73 ms
11.3 - training  | batch=15, size=128x128: 3887 ± 75 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 5216 ± 103 ms
12.2 - inference | batch=1, size=1024x1024: 5471 ± 214 ms
12.3 - training  | batch=4, size=256x256: 4465 ± 129 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1440 ± 95 ms
13.2 - training  | batch=1, size=128x128: 1983 ± 70 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1669 ± 90 ms
14.2 - training  | batch=10, size=1024x1536: 3830 ± 117 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7672 ± 46 ms
15.2 - training  | batch=1, size=512x512: 5117 ± 244 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2326 ± 55 ms
16.2 - training  | batch=1, size=384x384: 6267 ± 32 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5416 ± 122 ms
17.2 - training  | batch=10, size=64x64: 9795.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 11814 ± 492 ms
18.2 - training  | batch=10, size=1024x300: 8360 ± 169 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1752 ± 160 ms

Device Inference Score: 754
Device Training Score: 758
Device AI Score: 1512

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off

>>   AI-Benchmark-v.0.1.1   
>>   Let the AI Games begin..

*  TF Version: 1.14.0
*  Platform: Linux-4.15.0-72-generic-x86_64-with-Ubuntu-18.04-bionic
*  CPU: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz
*  CPU RAM: 126 GB

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

1.1 - inference | batch=50, size=224x224: 168 ± 13 ms
1.2 - training  | batch=50, size=224x224: 1322 ± 770 ms

2/19. Inception-V3

2.1 - inference | batch=20, size=346x346: 484 ± 60 ms
2.2 - training  | batch=20, size=346x346: 1948 ± 174 ms

3/19. Inception-V4

3.1 - inference | batch=10, size=346x346: 567 ± 95 ms
3.2 - training  | batch=10, size=346x346: 2867 ± 1464 ms

4/19. Inception-ResNet-V2

4.1 - inference | batch=10, size=346x346: 901 ± 136 ms
4.2 - training  | batch=8, size=346x346: 9704 ± 1089 ms

5/19. ResNet-V2-50

5.1 - inference | batch=10, size=346x346: 522 ± 90 ms
5.2 - training  | batch=10, size=346x346: 3502 ± 361 ms

6/19. ResNet-V2-152

6.1 - inference | batch=10, size=256x256: 682 ± 58 ms
6.2 - training  | batch=10, size=256x256: 7438 ± 2425 ms

7/19. VGG-16

7.1 - inference | batch=20, size=224x224: 632 ± 5 ms
7.2 - training  | batch=2, size=224x224: 782 ± 78 ms

8/19. SRCNN 9-5-5

8.1 - inference | batch=10, size=512x512: 780 ± 8 ms
8.2 - inference | batch=1, size=1536x1536: 707 ± 9 ms
8.3 - training  | batch=10, size=512x512: 2981 ± 97 ms

9/19. VGG-19 Super-Res

9.1 - inference | batch=10, size=256x256: 684 ± 5 ms
9.2 - inference | batch=1, size=1024x1024: 1177 ± 3 ms
9.3 - training  | batch=10, size=224x224: 3521 ± 89 ms

10/19. ResNet-SRGAN

10.1 - inference | batch=10, size=512x512: 2380 ± 23 ms
10.2 - inference | batch=1, size=1536x1536: 2180 ± 23 ms
10.3 - training  | batch=5, size=512x512: 4116 ± 49 ms

11/19. ResNet-DPED

11.1 - inference | batch=10, size=256x256: 2210 ± 177 ms
11.2 - inference | batch=1, size=1024x1024: 3792 ± 277 ms
11.3 - training  | batch=15, size=128x128: 3934 ± 110 ms

12/19. U-Net

12.1 - inference | batch=4, size=512x512: 4820 ± 146 ms
12.2 - inference | batch=1, size=1024x1024: 4887 ± 66 ms
12.3 - training  | batch=4, size=256x256: 4415 ± 78 ms

13/19. Nvidia-SPADE

13.1 - inference | batch=5, size=128x128: 1414 ± 87 ms
13.2 - training  | batch=1, size=128x128: 1950 ± 80 ms

14/19. ICNet

14.1 - inference | batch=5, size=1024x1536: 1671 ± 93 ms
14.2 - training  | batch=10, size=1024x1536: 3827 ± 96 ms

15/19. PSPNet

15.1 - inference | batch=5, size=720x720: 7698 ± 166 ms
15.2 - training  | batch=1, size=512x512: 5017 ± 72 ms

16/19. DeepLab

16.1 - inference | batch=2, size=512x512: 2329 ± 75 ms
16.2 - training  | batch=1, size=384x384: 7310 ± 472 ms

17/19. Pixel-RNN

17.1 - inference | batch=50, size=64x64: 5465 ± 109 ms
17.2 - training  | batch=10, size=64x64: 10418.0 ± 0.0 ms

18/19. LSTM-Sentiment

18.1 - inference | batch=100, size=1024x300: 10935 ± 108 ms
18.2 - training  | batch=10, size=1024x300: 8235 ± 203 ms

19/19. GNMT-Translation

19.1 - inference | batch=1, size=1x20: 1790 ± 205 ms

Device Inference Score: 932
Device Training Score: 784
Device AI Score: 1716

For more information and results, please visit http://ai-benchmark.com/alpha

kernel.numa_balancing = 0
numa_balancing=off
